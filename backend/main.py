from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
import uvicorn
import os
import re
import sys
import json
import threading
import subprocess
import uuid
import hashlib
from pathlib import Path
from typing import List, Dict, Optional
from urllib.parse import unquote

# å°†å½“å‰ç›®å½•ï¼ˆbackendï¼‰åŠ å…¥åˆ° Python è·¯å¾„ä¸­ï¼Œç¡®ä¿ app æ¨¡å—å¯ä»¥è¢«å¯¼å…¥
current_dir = Path(__file__).resolve().parent
if str(current_dir) not in sys.path:
    sys.path.append(str(current_dir))

from app.database import metadata_store
from app.ingestion import enricher

# è¯­ä¹‰æ ‡æ³¨å’Œå‘é‡åŒ–æ¨¡å—
try:
    from app.ingestion.semantic_annotator import SemanticAnnotator, LLMProviderManager, load_checkpoint, delete_checkpoint
    from app.ingestion.vectorizer import Vectorizer
    ANNOTATION_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ è¯­ä¹‰æ ‡æ³¨æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    ANNOTATION_AVAILABLE = False

# --- 1. å®šä¹‰æ•°æ®æ¨¡å‹ ---
class ScanRequest(BaseModel):
    path: str

class AnnotateRequest(BaseModel):
    movie_id: str
    subtitle_path: str
    movie_name: str = ""
    llm_provider: str = None
    # æ ‡æ³¨é…ç½®å‚æ•°
    batch_size: int = None
    concurrent_requests: int = None
    max_retries: int = None
    save_interval: int = None
    # æ–­ç‚¹ç»­æ ‡
    resume_from_checkpoint: bool = False

class VectorizeRequest(BaseModel):
    annotation_file: str = None  # å•æ–‡ä»¶æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
    movie_ids: List[str] = []  # æ‰¹é‡æ¨¡å¼ï¼šç”µå½±douban_idåˆ—è¡¨
    episode_items: List[Dict] = []  # æ‰¹é‡æ¨¡å¼ï¼šå‰§é›†åˆ—è¡¨ [{douban_id, episode_number}]
    provider_id: str = None  # embeddingæä¾›è€…ID

class SearchRequest(BaseModel):
    query: str
    limit: int = 10
    filters: Dict = None

class NextLineRequest(BaseModel):
    current_line_id: str
    limit: int = 10

# å…¨å±€çŠ¶æ€
annotation_status = {
    "running": False,
    "paused": False,
    "progress": 0,
    "total": 0,
    "current_movie": "",
    "error": None
}

# æ ‡æ³¨å–æ¶ˆäº‹ä»¶
annotation_cancel_event = threading.Event()
# æ ‡æ³¨æš‚åœäº‹ä»¶ï¼ˆset = æš‚åœï¼‰
annotation_pause_event = threading.Event()

vectorize_status = {
    "running": False,
    "progress": 0,
    "total": 0,
    "current_movie": "",
    "error": None,
    "queue_progress": {
        "current": 0,
        "total": 0
    }
}

# å‘é‡åŒ–å–æ¶ˆäº‹ä»¶
vectorize_cancel_event = threading.Event()

# --- 2. æ‰«æå™¨é€»è¾‘ (ç›´æ¥æ•´åˆåœ¨è¿™é‡Œæ–¹ä¾¿è°ƒè¯•) ---

# ffmpeg è·¯å¾„é…ç½®ï¼ˆæ”¯æŒé¡¹ç›®å†…ç½®çš„ ffmpegï¼‰
FFMPEG_PATH = Path(__file__).resolve().parent.parent / "ffmpeg" / "bin" / "ffmpeg.exe"
if not FFMPEG_PATH.exists():
    # å›é€€åˆ°ç³»ç»Ÿ PATH ä¸­çš„ ffmpeg
    FFMPEG_PATH = "ffmpeg"
else:
    FFMPEG_PATH = str(FFMPEG_PATH)

def extract_video_thumbnail(video_path: str, output_path: str) -> bool:
    """ä½¿ç”¨ ffmpeg æˆªå–è§†é¢‘é¦–å¸§ä½œä¸ºå°é¢"""
    try:
        cmd = [
            FFMPEG_PATH,
            '-i', video_path,
            '-ss', '00:00:01',  # è·³è¿‡ç¬¬1ç§’ï¼ˆé¿å…çº¯é»‘å¸§ï¼‰
            '-vframes', '1',
            '-q:v', '2',  # è¾ƒé«˜è´¨é‡
            '-y',  # è¦†ç›–å·²æœ‰æ–‡ä»¶
            output_path
        ]
        result = subprocess.run(cmd, capture_output=True, timeout=30)
        return Path(output_path).exists()
    except Exception as e:
        print(f"æˆªå–è§†é¢‘å°é¢å¤±è´¥: {e}")
        return False

class MediaScanner:
    def __init__(self, base_path):
        self.base_path = Path(base_path)
        # åŒ¹é…æ ¼å¼: "è±†ç“£ID-åå­—" æˆ– "è±†ç“£ID åå­—"
        self.folder_pattern = re.compile(r'^(\d+)[-\s]+(.+)$')
        self.video_exts = {'.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts'}
        self.sub_exts = {'.srt', '.ass', '.vtt'}
        # åŒ¹é…é›†æ•°çš„æ¨¡å¼ï¼šE01, EP01, ç¬¬01é›†, S01E01 ç­‰
        self.episode_pattern = re.compile(r'[Ee][Pp]?(\d+)|ç¬¬(\d+)[é›†è¯]|[Ss]\d+[Ee](\d+)', re.IGNORECASE)

    def extract_episode_number(self, filename: str) -> int:
        """ä»æ–‡ä»¶åä¸­æå–é›†æ•°"""
        match = self.episode_pattern.search(filename)
        if match:
            # è¿”å›ç¬¬ä¸€ä¸ªéç©ºçš„åŒ¹é…ç»„
            for group in match.groups():
                if group:
                    return int(group)
        return 0

    def scan(self):
        results = []
        if not self.base_path.exists():
            return []

        for folder_name in os.listdir(self.base_path):
            folder_path = self.base_path / folder_name
            if not folder_path.is_dir():
                continue

            # å°è¯•åŒ¹é…è±†ç“£IDæ ¼å¼
            match = self.folder_pattern.match(folder_name)
            if match:
                douban_id = match.group(1)
                movie_name = match.group(2).strip()
                is_custom_folder = False
            else:
                # éè±†ç“£IDæ ¼å¼çš„æ–‡ä»¶å¤¹ï¼Œä½¿ç”¨æ–‡ä»¶å¤¹åç§°çš„å“ˆå¸Œå€¼ç”Ÿæˆç¨³å®šçš„ID
                # è¿™æ ·åŒä¸€ä¸ªæ–‡ä»¶å¤¹æ¯æ¬¡æ‰«æéƒ½ä¼šå¾—åˆ°ç›¸åŒçš„IDï¼Œé¿å…é‡å¤å¯¼å…¥
                folder_hash = hashlib.md5(folder_name.encode('utf-8')).hexdigest()[:8]
                douban_id = f"custom_{folder_hash}"
                movie_name = folder_name.strip()
                is_custom_folder = True
                
            # æ”¶é›†æ‰€æœ‰è§†é¢‘å’Œå­—å¹•æ–‡ä»¶ï¼ˆæ”¯æŒç”µè§†å‰§å¤šé›†æƒ…å†µï¼‰
            video_files = []
            subtitle_files = []
            
            # éå†æ–‡ä»¶å¤¹å†…çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬å­ç›®å½•ï¼Œæ”¯æŒç”µè§†å‰§åˆ†å­£/åˆ†é›†ç»“æ„ï¼‰
            try:
                for root, dirs, files in os.walk(folder_path):
                    for file in files:
                        file_path = Path(root) / file
                        if file_path.suffix.lower() in self.video_exts:
                            video_files.append(str(file_path))
                        elif file_path.suffix.lower() in self.sub_exts:
                            subtitle_files.append(str(file_path))
            except Exception as e:
                print(f"è¯»å–æ–‡ä»¶å¤¹ {folder_name} å‡ºé”™: {e}")
            
            # åˆ¤æ–­æ˜¯ç”µå½±è¿˜æ˜¯ç”µè§†å‰§
            # è§„åˆ™ï¼šå¤šä¸ªè§†é¢‘æˆ–å¤šä¸ªå­—å¹• = ç”µè§†å‰§ï¼Œå•ä¸ªæ–‡ä»¶ = ç”µå½±
            total_files = max(len(video_files), len(subtitle_files))
            media_type = "tv" if total_files > 1 else "movie"
            
            # æ„å»º episodes æ•°ç»„
            episodes = []
            
            # ä¸ºæ¯ä¸ªè§†é¢‘æ–‡ä»¶åˆ›å»ºé›†æ•°æ˜ å°„
            video_episode_map = {}
            for vf in video_files:
                ep_num = self.extract_episode_number(Path(vf).stem)
                video_episode_map[vf] = ep_num
            
            # ä¸ºæ¯ä¸ªå­—å¹•æ–‡ä»¶åˆ›å»ºé›†æ•°æ˜ å°„
            subtitle_episode_map = {}
            for sf in subtitle_files:
                ep_num = self.extract_episode_number(Path(sf).stem)
                subtitle_episode_map[sf] = ep_num
            
            if media_type == "tv":
                # ç”µè§†å‰§ï¼šåˆ›å»ºå‰§é›†åˆ—è¡¨ï¼Œåˆå¹¶è§†é¢‘å’Œå­—å¹•æ–‡ä»¶
                used_subtitles = set()  # è®°å½•å·²åŒ¹é…çš„å­—å¹•æ–‡ä»¶
                
                if video_files:
                    # æœ‰è§†é¢‘æ–‡ä»¶çš„æƒ…å†µï¼Œå…ˆæŒ‰è§†é¢‘æ–‡ä»¶æ¥ç»„ç»‡
                    sorted_videos = sorted(video_files, key=lambda x: (video_episode_map.get(x, 0), Path(x).stem.lower()))
                
                    for idx, video_path in enumerate(sorted_videos):
                        ep_num = video_episode_map.get(video_path, 0)
                        video_stem = Path(video_path).stem.lower()
                        
                        # å°è¯•åŒ¹é…å¯¹åº”çš„å­—å¹•æ–‡ä»¶
                        matched_subtitle = None
                        for sub_path in subtitle_files:
                            if sub_path in used_subtitles:
                                continue
                            sub_stem = Path(sub_path).stem.lower()
                            # åŒ¹é…æ¡ä»¶ï¼šæ–‡ä»¶åç›¸ä¼¼æˆ–é›†æ•°ç›¸åŒ
                            if video_stem == sub_stem or video_stem in sub_stem or sub_stem in video_stem:
                                matched_subtitle = sub_path
                                used_subtitles.add(sub_path)
                                break
                            sub_ep_num = self.extract_episode_number(Path(sub_path).stem)
                            if ep_num > 0 and sub_ep_num > 0 and sub_ep_num == ep_num:
                                matched_subtitle = sub_path
                                used_subtitles.add(sub_path)
                                break
                        
                        episodes.append({
                            "episode_number": idx + 1,
                            "video_path": video_path,
                            "subtitle_path": matched_subtitle,
                            "video_filename": Path(video_path).name,
                            "subtitle_filename": Path(matched_subtitle).name if matched_subtitle else None
                        })
                    
                    # æ·»åŠ æœªåŒ¹é…çš„å­—å¹•æ–‡ä»¶ï¼ˆæ²¡æœ‰å¯¹åº”è§†é¢‘çš„å­—å¹•ï¼‰
                    unmatched_subtitles = [sf for sf in subtitle_files if sf not in used_subtitles]
                    for sub_path in sorted(unmatched_subtitles, key=lambda x: (subtitle_episode_map.get(x, 0), Path(x).stem.lower())):
                        episodes.append({
                            "episode_number": len(episodes) + 1,
                            "video_path": None,
                            "subtitle_path": sub_path,
                            "video_filename": None,
                            "subtitle_filename": Path(sub_path).name
                        })
                else:
                    # åªæœ‰å­—å¹•æ–‡ä»¶çš„æƒ…å†µ
                    sorted_subtitles = sorted(subtitle_files, key=lambda x: (subtitle_episode_map.get(x, 0), Path(x).stem.lower()))
                    for idx, sub_path in enumerate(sorted_subtitles):
                        episodes.append({
                            "episode_number": idx + 1,
                            "video_path": None,
                            "subtitle_path": sub_path,
                            "video_filename": None,
                            "subtitle_filename": Path(sub_path).name
                        })
                
                # é‡æ–°ç¼–å·å‰§é›†ï¼Œç¡®ä¿é¡ºåºæ­£ç¡®
                for idx, ep in enumerate(episodes):
                    ep["episode_number"] = idx + 1
            
            # è·³è¿‡ç©ºæ–‡ä»¶å¤¹ï¼ˆæ²¡æœ‰è§†é¢‘ä¹Ÿæ²¡æœ‰å­—å¹•ï¼‰
            if not video_files and not subtitle_files:
                continue
                
            # å–ç¬¬ä¸€ä¸ªè§†é¢‘å’Œå­—å¹•ä½œä¸ºä»£è¡¨
            video_file = video_files[0] if video_files else None
            subtitle_file = subtitle_files[0] if subtitle_files else None
            
            # å¯¹äºéè±†ç“£IDæ–‡ä»¶å¤¹ï¼Œå°è¯•æˆªå–è§†é¢‘é¦–å¸§ä½œä¸ºå°é¢
            local_poster = None
            if is_custom_folder and video_file:
                poster_path = folder_path / "poster.jpg"
                if not poster_path.exists():
                    if extract_video_thumbnail(video_file, str(poster_path)):
                        local_poster = str(poster_path)
                        print(f"âœ“ å·²æˆªå–è§†é¢‘é¦–å¸§ä½œä¸ºå°é¢: {poster_path.name}")
                else:
                    local_poster = str(poster_path)
            
            result_item = {
                "douban_id": douban_id,
                "title": movie_name,
                "folder": folder_name,
                "folder_path": str(folder_path),
                "video_path": video_file,
                "subtitle_path": subtitle_file,
                "video_count": len(video_files),
                "subtitle_count": len(subtitle_files),
                "media_type": media_type,
                "episodes": episodes if media_type == "tv" else [],
                "status": "ready" if video_file or subtitle_file else "missing_files",
                "is_custom": is_custom_folder  # æ ‡è®°æ˜¯å¦ä¸ºè‡ªå®šä¹‰æ–‡ä»¶å¤¹
            }
            
            # æ·»åŠ æœ¬åœ°å°é¢è·¯å¾„
            if local_poster:
                result_item["local_poster"] = local_poster
                
            results.append(result_item)
        return results

# --- 3. åˆ›å»º FastAPI åº”ç”¨ ---
app = FastAPI()

# é…ç½® CORSï¼Œå…è®¸ Tauri å‰ç«¯è®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸‹å»ºè®®è®¾ç½®ä¸ºå…·ä½“åœ°å€
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œ API è·¯ç”±
try:
    from app.api.llm import router as llm_router
    from app.api.config import router as config_router
    from app.api.settings import router as settings_router
    from app.api.model_providers import router as model_providers_router
    from app.api.ingestion_profiles import router as ingestion_profiles_router
    from app.api.prompt_templates import router as prompt_templates_router
    app.include_router(llm_router)
    app.include_router(config_router)
    app.include_router(settings_router)
    app.include_router(model_providers_router)
    app.include_router(ingestion_profiles_router)
    app.include_router(prompt_templates_router)
    print("âœ… LLMã€Configã€Settingsã€ModelProvidersã€IngestionProfilesã€PromptTemplates API è·¯ç”±å·²æ³¨å†Œ")
except ImportError as e:
    print(f"âš ï¸ API è·¯ç”±åŠ è½½å¤±è´¥: {e}")

@app.get("/")
async def root():
    return {"message": "CineGraph-AI Backend is running"}

@app.get("/api/poster/{poster_path:path}")
async def get_poster(poster_path: str):
    """è¿”å›æœ¬åœ°æµ·æŠ¥å›¾ç‰‡"""
    # è§£ç  URL ç¼–ç çš„è·¯å¾„
    decoded_path = unquote(poster_path)
    poster_file = Path(decoded_path)
    
    if not poster_file.exists():
        raise HTTPException(status_code=404, detail="Poster not found")
    
    if not poster_file.is_file():
        raise HTTPException(status_code=400, detail="Invalid poster path")
    
    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ˜¯å›¾ç‰‡æ–‡ä»¶
    allowed_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.gif'}
    if poster_file.suffix.lower() not in allowed_extensions:
        raise HTTPException(status_code=400, detail="Invalid file type")
    
    return FileResponse(poster_file, media_type="image/jpeg")

@app.get("/api/ingest/list")
async def list_movies():
    """è¿”å›å½“å‰æ•°æ®åº“ä¸­çš„æ‰€æœ‰å½±ç‰‡è®°å½•"""
    return {"movies": metadata_store.load_movies()}

@app.post("/api/ingest/scan")
async def scan_directory(request: ScanRequest):
    print(f"æ”¶åˆ°æ‰«æè¯·æ±‚è·¯å¾„: {request.path}")
    if not os.path.exists(request.path):
        raise HTTPException(status_code=400, detail="æ‰€é€‰è·¯å¾„ä¸å­˜åœ¨")
    
    scanner = MediaScanner(request.path)
    movies = scanner.scan()
    
    # è·å–å·²å­˜åœ¨çš„å½±ç‰‡è®°å½•ï¼Œç”¨äºæ¯”è¾ƒ
    existing_movies = metadata_store.load_movies()
    existing_map = {m.get('douban_id'): m for m in existing_movies}
    
    # æ ‡è®°æ¯ä¸ªæ‰«æç»“æœçš„çŠ¶æ€ï¼šnewï¼ˆæ–°å¢ï¼‰ã€updatedï¼ˆæœ‰æ›´æ–°ï¼‰ã€unchangedï¼ˆæ— å˜åŒ–ï¼‰
    for movie in movies:
        movie_id = movie.get('douban_id')
        if movie_id not in existing_map:
            movie['_scan_status'] = 'new'
        else:
            # æ¯”è¾ƒæ–‡ä»¶æ•°é‡æ˜¯å¦æœ‰å˜åŒ–
            existing = existing_map[movie_id]
            old_video_count = existing.get('video_count', 0)
            old_subtitle_count = existing.get('subtitle_count', 0)
            
            new_video_count = movie.get('video_count', 0)
            new_subtitle_count = movie.get('subtitle_count', 0)
            
            # å¯¹äºç”µè§†å‰§ï¼Œé¢å¤–æ¯”è¾ƒå‰§é›†æ•°
            has_episode_change = False
            if movie.get('media_type') == 'tv':
                old_episode_count = len(existing.get('episodes', []))
                new_episode_count = len(movie.get('episodes', []))
                has_episode_change = (new_episode_count != old_episode_count)
            
            if (new_video_count != old_video_count or 
                new_subtitle_count != old_subtitle_count or
                has_episode_change):
                movie['_scan_status'] = 'updated'
            else:
                movie['_scan_status'] = 'unchanged'
    
    new_count = sum(1 for m in movies if m.get('_scan_status') == 'new')
    updated_count = sum(1 for m in movies if m.get('_scan_status') == 'updated')
    unchanged_count = sum(1 for m in movies if m.get('_scan_status') == 'unchanged')
    
    print(f"æ‰«æå®Œæˆï¼Œå…± {len(movies)} éƒ¨ï¼šæ–°å¢ {new_count}ï¼Œæ›´æ–° {updated_count}ï¼Œæ— å˜åŒ– {unchanged_count}")
    return {
        "movies": movies, 
        "total": len(movies),
        "new_count": new_count,
        "updated_count": updated_count,
        "unchanged_count": unchanged_count
    }


# ==================== å½±ç‰‡åº“API ====================

def scan_annotation_files() -> dict:
    """æ‰«æannotationsæ–‡ä»¶å¤¹ï¼Œè¿”å›å·²æ ‡æ³¨çš„movie_idé›†åˆ"""
    annotations_dir = Path(__file__).parent / "data" / "annotations"
    annotated = {}
    
    if annotations_dir.exists():
        for f in annotations_dir.glob("*_annotated.json"):
            # æå–movie_id (å»æ‰_annotatedåç¼€)
            movie_id = f.stem.replace("_annotated", "")
            annotated[movie_id] = str(f)
    
    return annotated


@app.get("/api/library/list")
async def list_library():
    """åˆ—å‡ºå½±ç‰‡åº“ä¸­çš„æ‰€æœ‰å½±ç‰‡ï¼Œå¹¶å…³è”æ ‡æ³¨çŠ¶æ€"""
    try:
        movies = metadata_store.load_movies()
        
        # æ‰«æå·²æ ‡æ³¨çš„æ–‡ä»¶
        annotated_files = scan_annotation_files()
        
        # ä¸ºæ¯ä¸ªå½±ç‰‡/å‰§é›†å…³è”æ ‡æ³¨çŠ¶æ€
        for movie in movies:
            movie_id = movie.get('douban_id', '')
            
            # ç”µè§†å‰§ï¼šæ£€æŸ¥æ¯é›†çš„æ ‡æ³¨çŠ¶æ€
            if movie.get('media_type') == 'tv' and movie.get('episodes'):
                all_annotated = True
                any_annotated = False
                
                for ep in movie.get('episodes', []):
                    ep_id = f"{movie_id}_ep{ep.get('episode_number', 0)}"
                    if ep_id in annotated_files:
                        ep['annotation_path'] = annotated_files[ep_id]
                        any_annotated = True
                    else:
                        if ep.get('subtitle_path'):  # åªæœ‰æœ‰å­—å¹•çš„æ‰ç®—æœªæ ‡æ³¨
                            all_annotated = False
                
                # æ•´ä½“æ ‡æ³¨çŠ¶æ€
                if any_annotated:
                    movie['status_annotate'] = 'done' if all_annotated else 'partial'
                else:
                    movie['status_annotate'] = 'pending'
                    
            else:
                # ç”µå½±ï¼šæ£€æŸ¥å•ä¸ªæ ‡æ³¨çŠ¶æ€
                if movie_id in annotated_files:
                    movie['annotation_path'] = annotated_files[movie_id]
                    movie['status_annotate'] = 'done'
                else:
                    movie['status_annotate'] = 'pending'
        
        return {"items": movies, "total": len(movies)}
    except Exception as e:
        print(f"åŠ è½½å½±ç‰‡åº“å¤±è´¥: {e}")
        return {"items": [], "total": 0}


@app.delete("/api/library/delete/{movie_id}")
async def delete_from_library(movie_id: str):
    """ä»å½±ç‰‡åº“ä¸­åˆ é™¤æŒ‡å®šå½±ç‰‡ï¼ŒåŒæ—¶æ¸…ç†æ ‡æ³¨æ–‡ä»¶å’Œå‘é‡åŒ–æ•°æ®"""
    try:
        # å…ˆè·å–å½±ç‰‡ä¿¡æ¯ï¼ˆç”¨äºæ¸…ç†å…³è”æ•°æ®ï¼‰
        movie_info = metadata_store.get_movie(movie_id)
        
        success = metadata_store.delete_movie(movie_id)
        
        if not success:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥å½±ç‰‡")
        
        # æ¸…ç†æ ‡æ³¨æ–‡ä»¶
        annotations_dir = Path(__file__).parent / "data" / "annotations"
        deleted_annotations = []
        if annotations_dir.exists():
            # åˆ é™¤ç”µå½±æ ‡æ³¨ï¼šmovie_id_annotated.json
            ann_file = annotations_dir / f"{movie_id}_annotated.json"
            if ann_file.exists():
                ann_file.unlink()
                deleted_annotations.append(str(ann_file.name))
            # åˆ é™¤å‰§é›†æ ‡æ³¨ï¼šmovie_id_epN_annotated.json
            for f in annotations_dir.glob(f"{movie_id}_ep*_annotated.json"):
                f.unlink()
                deleted_annotations.append(str(f.name))
        
        if deleted_annotations:
            print(f"\U0001f5d1\ufe0f å·²åˆ é™¤æ ‡æ³¨æ–‡ä»¶: {', '.join(deleted_annotations)}")
        
        # æ¸…ç†å‘é‡åŒ–æ•°æ®ï¼ˆChromaDBï¼‰
        try:
            if ANNOTATION_AVAILABLE:
                vectorizer_instance = Vectorizer()
                # åˆ é™¤ç”µå½±å‘é‡æ•°æ®
                vectorizer_instance.store.delete_by_movie(movie_id)
                # å¦‚æœæ˜¯ç”µè§†å‰§ï¼Œä¹Ÿåˆ é™¤æ¯é›†çš„å‘é‡æ•°æ®
                if movie_info and movie_info.get('media_type') == 'tv':
                    for ep in movie_info.get('episodes', []):
                        ep_id = f"{movie_id}_ep{ep.get('episode_number', 0)}"
                        vectorizer_instance.store.delete_by_movie(ep_id)
                print(f"\U0001f5d1\ufe0f å·²æ¸…ç†å‘é‡åŒ–æ•°æ®: {movie_id}")
        except Exception as e:
            print(f"\u26a0\ufe0f æ¸…ç†å‘é‡åŒ–æ•°æ®å¤±è´¥ ({movie_id}): {e}")
        
        return {"status": "ok", "deleted": movie_id, "cleaned_annotations": deleted_annotations}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/library/delete-episode/{movie_id}/{episode_number}")
async def delete_episode_from_library(movie_id: str, episode_number: int):
    """ä»å½±ç‰‡åº“ä¸­åˆ é™¤æŒ‡å®šå½±ç‰‡çš„æŸä¸€é›†ï¼ŒåŒæ—¶æ¸…ç†å…³è”çš„æ ‡æ³¨å’Œå‘é‡æ•°æ®"""
    try:
        success, remaining = metadata_store.delete_episode(movie_id, episode_number)
        
        if not success:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥é›†")
        
        # æ¸…ç†è¯¥é›†çš„æ ‡æ³¨æ–‡ä»¶
        annotations_dir = Path(__file__).parent / "data" / "annotations"
        ep_ann_file = annotations_dir / f"{movie_id}_ep{episode_number}_annotated.json"
        if ep_ann_file.exists():
            ep_ann_file.unlink()
            print(f"\U0001f5d1\ufe0f å·²åˆ é™¤å‰§é›†æ ‡æ³¨: {ep_ann_file.name}")
        
        # æ¸…ç†è¯¥é›†çš„å‘é‡åŒ–æ•°æ®
        try:
            if ANNOTATION_AVAILABLE:
                ep_id = f"{movie_id}_ep{episode_number}"
                vectorizer_instance = Vectorizer()
                vectorizer_instance.store.delete_by_movie(ep_id)
                print(f"\U0001f5d1\ufe0f å·²æ¸…ç†å‰§é›†å‘é‡æ•°æ®: {ep_id}")
        except Exception as e:
            print(f"\u26a0\ufe0f æ¸…ç†å‰§é›†å‘é‡æ•°æ®å¤±è´¥: {e}")
        
        return {"status": "ok", "deleted_episode": episode_number, "remaining_episodes": remaining}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/library/update/{movie_id}")
async def update_library_item(movie_id: str, request: Request):
    """æ›´æ–°å½±ç‰‡åº“ä¸­çš„æŒ‡å®šå½±ç‰‡ä¿¡æ¯"""
    try:
        update_data = await request.json()
        
        success = metadata_store.update_movie(movie_id, update_data)
        
        if not success:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥å½±ç‰‡")
        
        return {"status": "ok", "updated": movie_id}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/ingest/import")
async def import_scan_results(request: Request):
    """å°†æ‰«æç»“æœæŒä¹…åŒ–åˆ°æ•°æ®åº“ä¸­ã€‚

    æ¥å— JSON åˆ—è¡¨ [{}, ...] æˆ– { "movies": [...] } æ ¼å¼ã€‚
    ä¼šä¸ºæ¯éƒ¨å½±ç‰‡åˆ›å»ºæ•°æ®åº“è®°å½•ï¼ˆå« episodesï¼‰ï¼Œå¹¶è®¾ç½® status_import='done'ã€‚
    """
    try:
        payload = await request.json()
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid JSON body")

    # æ”¯æŒä¸¤ç§æ ¼å¼
    if isinstance(payload, dict) and 'movies' in payload:
        movies = payload.get('movies')
    else:
        movies = payload

    if not isinstance(movies, list):
        raise HTTPException(status_code=400, detail="Expected a JSON list of movie objects")

    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å¢æˆ–æ›´æ–°çš„å†…å®¹
    has_changes = any(m.get('_scan_status') in ('new', 'updated') for m in movies)
    
    # è¿‡æ»¤ï¼šåªä¿å­˜ new å’Œ updated çš„å½±ç‰‡ï¼Œè·³è¿‡ unchanged
    movies_to_save = [m for m in movies if m.get('_scan_status') in ('new', 'updated')]
    unchanged_count = sum(1 for m in movies if m.get('_scan_status') == 'unchanged')
    
    # ç”Ÿæˆå¯¼å…¥æ‰¹æ¬¡å·
    import_batch = f"batch_{uuid.uuid4().hex[:8]}"
    
    # æ”¶é›†éœ€è¦ enrichment çš„è±†ç“£IDï¼ˆåªé’ˆå¯¹æ–°å¢/æ›´æ–°çš„éè‡ªå®šä¹‰å½±ç‰‡ï¼‰
    enrich_ids = []
    
    # å‡†å¤‡å¯¼å…¥æ•°æ®ï¼šç§»é™¤ä¸´æ—¶å­—æ®µï¼Œè®¾ç½®çŠ¶æ€
    for m in movies_to_save:
        scan_status = m.pop('_scan_status', None)
        m.pop('is_custom', None)
        # æ ‡è®°å¯¼å…¥çŠ¶æ€ä¸ºå®Œæˆ
        m['status_import'] = 'done'
        m['import_batch'] = import_batch
        
        # æ”¶é›†éœ€è¦ enrichment çš„è±†ç“£ID
        douban_id = m.get('douban_id', '')
        if douban_id and not str(douban_id).startswith('custom_'):
            enrich_ids.append(str(douban_id))
    
    try:
        if movies_to_save:
            metadata_store.save_movies(movies_to_save)
            print(f"âœ… å¯¼å…¥å®Œæˆï¼š{len(movies_to_save)} éƒ¨å½±ç‰‡å·²å†™å…¥æ•°æ®åº“ (æ‰¹æ¬¡: {import_batch})")
            if unchanged_count > 0:
                print(f"   â­ï¸ è·³è¿‡ {unchanged_count} éƒ¨æ— å˜åŒ–çš„å½±ç‰‡")
        else:
            print(f"[*] æ‰€æœ‰ {len(movies)} éƒ¨å½±ç‰‡å‡æ— å˜åŒ–ï¼Œè·³è¿‡å†™å…¥")
        
        # åªæœ‰åœ¨æœ‰æ–°å¢æˆ–æ›´æ–°çš„éè‡ªå®šä¹‰å½±ç‰‡æ—¶æ‰å¯åŠ¨ enrichment
        enrichment_started = False
        if has_changes and enrich_ids:
            try:
                enricher.start_enrichment(target_ids=enrich_ids)
                enrichment_started = True
            except Exception:
                print("âš ï¸ å¯åŠ¨å…ƒæ•°æ®æŠ“å–å¤±è´¥ï¼Œä½†å¯¼å…¥å·²å®Œæˆ")
        else:
            print("[*] æ— éœ€æŠ“å–å…ƒæ•°æ®")
        
        return {
            "status": "ok", 
            "count": len(movies_to_save),
            "skipped": unchanged_count,
            "import_batch": import_batch,
            "enrichment_started": enrichment_started
        }
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/ingest/enrich/start")
async def enrich_start():
    """Start background enrichment (fetch Douban metadata for saved movies)."""
    result = enricher.start_enrichment()
    return result


@app.get("/api/ingest/enrich/status")
async def enrich_status():
    """Get enrichment progress status."""
    return enricher.get_status()


@app.post("/api/ingest/import-debug")
async def import_scan_debug(request: Request):
    """Debug endpoint: print raw body bytes and attempt to parse JSON."""
    body = await request.body()
    print(f"DEBUG RAW BODY ({len(body)} bytes):", body[:1000])
    try:
        payload = await request.json()
        print("DEBUG parsed payload type:", type(payload))
    except Exception as e:
        print("DEBUG parse error:", e)
        raise HTTPException(status_code=400, detail="There was an error parsing the body")
    return {"status": "ok", "received_bytes": len(body)}


# ==================== è¯­ä¹‰æ ‡æ³¨API ====================

@app.get("/api/annotation/providers")
async def list_llm_providers():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„LLMæä¾›è€…ï¼ˆå…¼å®¹æ—§æ¥å£ï¼Œä¼˜å…ˆä»æ•°æ®åº“è¯»å–ï¼‰"""
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="è¯­ä¹‰æ ‡æ³¨æ¨¡å—æœªåŠ è½½")
    
    # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“
    try:
        from app.core.model_provider_service import get_model_provider_service
        service = get_model_provider_service()
        providers = service.list_providers(category='llm')
        return {"providers": providers}
    except Exception:
        pass
    
    # å›é€€åˆ° LLMProviderManager
    manager = LLMProviderManager()
    return {"providers": manager.list_providers()}


@app.post("/api/annotation/test-connection")
async def test_llm_connection(request: dict):
    """æµ‹è¯•LLMè¿æ¥"""
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="è¯­ä¹‰æ ‡æ³¨æ¨¡å—æœªåŠ è½½")
    
    provider_id = request.get("provider_id")
    if not provider_id:
        return {"success": False, "error": "æœªæŒ‡å®šæ¨¡å‹ID"}
    
    try:
        manager = LLMProviderManager()
        provider = manager.get_provider(provider_id)
        
        if not provider:
            return {"success": False, "error": f"æœªæ‰¾åˆ°æ¨¡å‹: {provider_id}"}
        
        # ä½¿ç”¨Providerè‡ªå¸¦çš„test_connectionæ–¹æ³•
        result = provider.test_connection()
        return result
                
    except ValueError as e:
        return {"success": False, "error": str(e)}
    except Exception as e:
        return {"success": False, "error": f"æµ‹è¯•å¤±è´¥: {str(e)}"}


@app.post("/api/annotation/start")
async def start_annotation(request: AnnotateRequest, background_tasks: BackgroundTasks):
    """å¼€å§‹å¯¹å­—å¹•æ–‡ä»¶è¿›è¡Œè¯­ä¹‰æ ‡æ³¨"""
    global annotation_status
    
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="è¯­ä¹‰æ ‡æ³¨æ¨¡å—æœªåŠ è½½")
    
    if annotation_status["running"]:
        raise HTTPException(status_code=409, detail="æ ‡æ³¨ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­")
    
    if not os.path.exists(request.subtitle_path):
        raise HTTPException(status_code=400, detail=f"å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {request.subtitle_path}")
    
    # å¯åŠ¨åå°ä»»åŠ¡
    annotation_cancel_event.clear()
    annotation_pause_event.clear()
    background_tasks.add_task(
        run_annotation,
        request.movie_id,
        request.subtitle_path,
        request.movie_name or request.movie_id,
        request.llm_provider,
        request.batch_size,
        request.concurrent_requests,
        request.max_retries,
        request.save_interval,
        request.resume_from_checkpoint
    )
    
    return {"status": "started", "movie_id": request.movie_id}


def run_annotation(
    movie_id: str, 
    subtitle_path: str, 
    movie_name: str, 
    llm_provider: str = None,
    batch_size: int = None,
    concurrent_requests: int = None,
    max_retries: int = None,
    save_interval: int = None,
    resume_from_checkpoint: bool = False
):
    """åå°æ‰§è¡Œè¯­ä¹‰æ ‡æ³¨ï¼ˆæ”¯æŒå¢é‡ä¿å­˜ã€æš‚åœ/æ¢å¤ã€checkpointï¼‰"""
    global annotation_status
    
    annotation_status = {
        "running": True,
        "paused": False,
        "progress": 0,
        "total": 0,
        "current_movie": movie_name,
        "error": None
    }
    
    try:
        # ä¼ é€’åŠ¨æ€å‚æ•°åˆ°æ ‡æ³¨å™¨
        annotator = SemanticAnnotator(
            llm_provider=llm_provider,
            max_retries=max_retries,
            save_interval=save_interval
        )
        
        def progress_callback(current, total):
            annotation_status["progress"] = current
            annotation_status["total"] = total
        
        # æ‰“å°ä½¿ç”¨çš„å‚æ•°
        print(f"ğŸ“‹ æ ‡æ³¨å‚æ•°: batch_size={batch_size}, concurrent={concurrent_requests}, max_retries={max_retries}, save_interval={save_interval}")
        print(f"ğŸ“‹ å½±ç‰‡ID: {movie_id}, å½±ç‰‡åç§°: {movie_name}, ç»­æ ‡={resume_from_checkpoint}")
        
        annotations = annotator.annotate_subtitle_file(
            subtitle_path=subtitle_path,
            movie_name=movie_name,
            movie_id=movie_id,
            window_size=5,
            max_workers=concurrent_requests,
            batch_size=batch_size,
            progress_callback=progress_callback,
            cancel_event=annotation_cancel_event,
            pause_event=annotation_pause_event,
            resume_from_checkpoint=resume_from_checkpoint
        )
        
        # æš‚åœæ—¶ï¼šå¢é‡ä¿å­˜å·²ç”± annotator å†…éƒ¨å®Œæˆï¼Œä¿æŒ paused çŠ¶æ€
        if annotation_pause_event.is_set():
            annotation_status["running"] = False
            annotation_status["paused"] = True
            annotation_status["current_movie"] = f"å·²æš‚åœ - {movie_name}"
            print(f"â¸ï¸ æ ‡æ³¨å·²æš‚åœ: {movie_name}ï¼Œè¿›åº¦å·²ä¿å­˜")
            return
        
        # å–æ¶ˆæ—¶ï¼šå¢é‡ä¿å­˜å·²ç”± annotator å†…éƒ¨å®Œæˆ
        if annotation_cancel_event.is_set():
            annotation_status["running"] = False
            annotation_status["paused"] = False
            annotation_status["current_movie"] = f"å·²å–æ¶ˆ - {movie_name}"
            annotation_status["error"] = "å·²å–æ¶ˆï¼ˆå·²ä¿å­˜è¿›åº¦ï¼‰"
            print(f"âš ï¸ æ ‡æ³¨å·²å–æ¶ˆ: {movie_name}ï¼Œè¿›åº¦å·²ä¿å­˜")
            return
        
        # æ­£å¸¸å®Œæˆï¼ˆannotatorå†…éƒ¨å·²ä¿å­˜å¹¶æ¸…ç†checkpointï¼‰
        annotation_status["running"] = False
        annotation_status["paused"] = False
        annotation_status["progress"] = annotation_status["total"]
        print(f"âœ… æ ‡æ³¨å®Œæˆ: {movie_name}")
        
    except Exception as e:
        annotation_status["running"] = False
        annotation_status["paused"] = False
        annotation_status["error"] = str(e)
        print(f"âŒ æ ‡æ³¨å¤±è´¥: {e}")


@app.get("/api/annotation/status")
async def get_annotation_status():
    """è·å–æ ‡æ³¨è¿›åº¦"""
    return annotation_status


@app.post("/api/annotation/pause")
async def pause_annotation():
    """æš‚åœå½“å‰æ ‡æ³¨ä»»åŠ¡ï¼ˆä¿ç•™checkpointï¼Œå¯æ¢å¤ï¼‰"""
    if not annotation_status.get("running"):
        return {"success": False, "error": "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„æ ‡æ³¨ä»»åŠ¡"}
    annotation_pause_event.set()
    annotation_status["paused"] = True
    return {"success": True, "message": "æš‚åœä¿¡å·å·²å‘é€ï¼Œæ ‡æ³¨å°†åœ¨å½“å‰æ‰¹æ¬¡å®Œæˆåæš‚åœ"}


@app.post("/api/annotation/resume")
async def resume_annotation():
    """æ¢å¤æš‚åœçš„æ ‡æ³¨ä»»åŠ¡
    æ³¨æ„ï¼šæ¢å¤å®é™…ä¸Šæ˜¯ç”±å‰ç«¯é‡æ–°å‘é€ /api/annotation/start å¹¶è®¾ç½® resume_from_checkpoint=true æ¥å®ç°çš„ã€‚
    æ­¤APIä»…ç”¨äºåœ¨åŒä¸€ä¸ªæ ‡æ³¨çº¿ç¨‹æš‚åœæœŸé—´æ¢å¤ï¼ˆçº¿ç¨‹ä»ç„¶é˜»å¡ç­‰å¾…ä¸­ï¼‰ã€‚
    """
    if annotation_pause_event.is_set():
        annotation_pause_event.clear()
        annotation_status["paused"] = False
        return {"success": True, "message": "æ¢å¤ä¿¡å·å·²å‘é€"}
    return {"success": False, "error": "æ ‡æ³¨æœªå¤„äºæš‚åœçŠ¶æ€"}


@app.post("/api/annotation/cancel")
async def cancel_annotation():
    """å–æ¶ˆå½“å‰æ ‡æ³¨ä»»åŠ¡ï¼ˆå¢é‡ä¿å­˜å·²å®Œæˆéƒ¨åˆ†ï¼‰"""
    annotation_cancel_event.set()
    # å¦‚æœå¤„äºæš‚åœçŠ¶æ€ï¼Œä¹Ÿéœ€è¦è§£é™¤æš‚åœè®©çº¿ç¨‹èƒ½é€€å‡º
    if annotation_pause_event.is_set():
        annotation_pause_event.clear()
    annotation_status["running"] = False
    annotation_status["paused"] = False
    annotation_status["error"] = "å·²å–æ¶ˆï¼ˆå·²ä¿å­˜è¿›åº¦ï¼‰"
    return {"success": True}


@app.get("/api/annotation/checkpoint/{movie_id}")
async def get_checkpoint(movie_id: str):
    """è·å–æŒ‡å®šå½±ç‰‡çš„checkpointä¿¡æ¯ï¼ˆç”¨äºå‰ç«¯åˆ¤æ–­æ˜¯å¦å¯ä»¥ç»­æ ‡ï¼‰"""
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="è¯­ä¹‰æ ‡æ³¨æ¨¡å—æœªåŠ è½½")
    
    cp = load_checkpoint(movie_id)
    if cp:
        return {"has_checkpoint": True, "checkpoint": cp}
    return {"has_checkpoint": False, "checkpoint": None}


@app.delete("/api/annotation/checkpoint/{movie_id}")
async def remove_checkpoint(movie_id: str):
    """åˆ é™¤æŒ‡å®šå½±ç‰‡çš„checkpointï¼ˆé‡æ–°æ ‡æ³¨æ—¶ä½¿ç”¨ï¼‰"""
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="è¯­ä¹‰æ ‡æ³¨æ¨¡å—æœªåŠ è½½")
    
    delete_checkpoint(movie_id)
    return {"success": True}


@app.get("/api/annotation/list")
async def list_annotations():
    """åˆ—å‡ºæ‰€æœ‰å·²æ ‡æ³¨çš„æ–‡ä»¶"""
    output_dir = Path(__file__).parent / "data" / "annotations"
    if not output_dir.exists():
        return {"annotations": []}
    
    annotations = []
    for f in output_dir.glob("*_annotated.json"):
        try:
            with open(f, "r", encoding="utf-8") as file:
                data = json.load(file)
            annotations.append({
                "file": str(f),
                "movie_id": f.stem.replace("_annotated", ""),
                "line_count": len(data),
                "size": f.stat().st_size
            })
        except Exception:
            continue
    
    return {"annotations": annotations}


# ==================== å‘é‡åŒ–API ====================

@app.post("/api/vectorize/start")
async def start_vectorize(request: VectorizeRequest, background_tasks: BackgroundTasks):
    """å¼€å§‹å‘é‡åŒ–æ ‡æ³¨æ•°æ®"""
    global vectorize_status
    
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="å‘é‡åŒ–æ¨¡å—æœªåŠ è½½")
    
    if vectorize_status["running"]:
        raise HTTPException(status_code=409, detail="å‘é‡åŒ–ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­")
    
    # æ”¶é›†æ‰€æœ‰éœ€è¦å‘é‡åŒ–çš„æ ‡æ³¨æ–‡ä»¶
    annotation_files = []
    
    # å•æ–‡ä»¶æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
    if request.annotation_file:
        if not os.path.exists(request.annotation_file):
            raise HTTPException(status_code=400, detail=f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {request.annotation_file}")
        annotation_files.append(request.annotation_file)
    
    # æ‰¹é‡æ¨¡å¼ï¼šæ ¹æ®movie_idså’Œepisode_itemsæŸ¥æ‰¾æ ‡æ³¨æ–‡ä»¶
    annotations_dir = Path(current_dir) / "data" / "annotations"
    
    # å¤„ç†ç”µå½±
    for movie_id in request.movie_ids:
        # å°è¯•æŸ¥æ‰¾å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
        pattern = f"{movie_id}_annotated.json"
        matches = list(annotations_dir.glob(pattern))
        if matches:
            annotation_files.append(str(matches[0]))
        else:
            # å°è¯•ä»metadataè·å–annotation_path
            try:
                metadata = metadata_store.get_movie(movie_id)
                if metadata and metadata.get("annotation_path"):
                    ann_path = metadata["annotation_path"]
                    if os.path.exists(ann_path):
                        annotation_files.append(ann_path)
            except Exception:
                pass
    
    # å¤„ç†å‰§é›†
    for ep_item in request.episode_items:
        douban_id = ep_item.get("douban_id")
        episode_number = ep_item.get("episode_number")
        if douban_id and episode_number:
            pattern = f"{douban_id}_ep{episode_number}_annotated.json"
            matches = list(annotations_dir.glob(pattern))
            if matches:
                annotation_files.append(str(matches[0]))
    
    if not annotation_files:
        raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°ä»»ä½•æ ‡æ³¨æ–‡ä»¶")
    
    # æ¸…é™¤å–æ¶ˆäº‹ä»¶
    vectorize_cancel_event.clear()
    
    background_tasks.add_task(run_vectorize_batch, annotation_files, request.provider_id)
    
    return {"status": "started", "total_files": len(annotation_files)}


def run_vectorize_batch(annotation_files: List[str], provider_id: str = None):
    """åå°æ‰§è¡Œæ‰¹é‡å‘é‡åŒ–"""
    global vectorize_status
    
    total_files = len(annotation_files)
    vectorize_status = {
        "running": True,
        "progress": 0,
        "total": 0,
        "current_movie": "",
        "error": None,
        "queue_progress": {
            "current": 0,
            "total": total_files
        }
    }
    
    try:
        vectorizer = Vectorizer()
        total_count = 0
        
        for idx, annotation_file in enumerate(annotation_files):
            # æ£€æŸ¥æ˜¯å¦å–æ¶ˆ
            if vectorize_cancel_event.is_set():
                vectorize_status["current_movie"] = "å·²å–æ¶ˆ"
                vectorize_status["running"] = False
                return
            
            # æ›´æ–°å½“å‰å¤„ç†çš„æ–‡ä»¶
            filename = os.path.basename(annotation_file)
            vectorize_status["current_movie"] = filename
            vectorize_status["queue_progress"]["current"] = idx + 1
            vectorize_status["progress"] = 0
            vectorize_status["total"] = 0
            
            def progress_callback(current, total):
                if vectorize_cancel_event.is_set():
                    raise Exception("å‘é‡åŒ–å·²å–æ¶ˆ")
                vectorize_status["progress"] = current
                vectorize_status["total"] = total
            
            try:
                count = vectorizer.vectorize_annotations(
                    annotations_path=annotation_file,
                    batch_size=50,
                    progress_callback=progress_callback
                )
                
                # å†æ¬¡æ£€æŸ¥æ˜¯å¦å–æ¶ˆï¼ˆåœ¨å…¥åº“å®Œæˆåï¼‰
                if vectorize_cancel_event.is_set():
                    # å–æ¶ˆæ—¶ä¸æ›´æ–°metadataï¼Œå½“å‰æ–‡ä»¶çš„å‘é‡æ•°æ®å¯èƒ½ä¸å®Œæ•´
                    # ChromaDBçš„upsertæ˜¯åŸå­æ“ä½œï¼Œå·²å…¥åº“çš„æ•°æ®ä¼šä¿ç•™
                    vectorize_status["current_movie"] = "å·²å–æ¶ˆï¼ˆå½“å‰æ–‡ä»¶æœªå®Œæˆï¼‰"
                    vectorize_status["running"] = False
                    print(f"âš ï¸ å‘é‡åŒ–å·²å–æ¶ˆï¼Œæ–‡ä»¶ {filename} å¯èƒ½æœªå®Œæ•´å…¥åº“")
                    return
                
                total_count += count
                
                # åªæœ‰å®Œæ•´å¤„ç†åæ‰æ›´æ–°metadata
                base_name = os.path.basename(annotation_file)
                match = re.match(r"(\d+)(?:_ep\d+)?_annotated\.json", base_name)
                if match:
                    douban_id = match.group(1)
                    try:
                        vector_path = annotation_file.replace("_annotated.json", "_vectorized")
                        metadata_store.update_movie(douban_id, {
                            "status_vectorize": "done",
                            "vector_path": vector_path
                        })
                    except Exception as e:
                        print(f"âš ï¸ æ›´æ–°metadataå¤±è´¥: {e}")
                        
            except Exception as e:
                if "å·²å–æ¶ˆ" in str(e):
                    vectorize_status["current_movie"] = "å·²å–æ¶ˆï¼ˆå½“å‰æ–‡ä»¶æœªå®Œæˆï¼‰"
                    vectorize_status["running"] = False
                    print(f"âš ï¸ å‘é‡åŒ–å·²å–æ¶ˆï¼Œæ–‡ä»¶ {filename} æœªå…¥åº“")
                    return
                print(f"âš ï¸ å‘é‡åŒ– {filename} å¤±è´¥: {e}")
                continue
        
        vectorize_status["running"] = False
        vectorize_status["current_movie"] = f"å®Œæˆ ({total_count} æ¡)"
        vectorize_status["queue_progress"]["current"] = total_files
        
    except Exception as e:
        vectorize_status["running"] = False
        vectorize_status["error"] = str(e)
        print(f"âŒ å‘é‡åŒ–å¤±è´¥: {e}")


def run_vectorize(annotation_file: str):
    """åå°æ‰§è¡Œå‘é‡åŒ–ï¼ˆå•æ–‡ä»¶ï¼Œå‘åå…¼å®¹ï¼‰"""
    run_vectorize_batch([annotation_file])


@app.post("/api/vectorize/cancel")
async def cancel_vectorize():
    """å–æ¶ˆå‘é‡åŒ–ä»»åŠ¡"""
    global vectorize_status
    
    if not vectorize_status["running"]:
        return {"status": "not_running"}
    
    vectorize_cancel_event.set()
    return {"status": "cancelling"}


@app.get("/api/vectorize/status")
async def get_vectorize_status():
    """è·å–å‘é‡åŒ–è¿›åº¦"""
    return vectorize_status


@app.get("/api/vectorize/stats")
async def get_vector_stats():
    """è·å–å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯"""
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="å‘é‡åŒ–æ¨¡å—æœªåŠ è½½")
    
    try:
        vectorizer = Vectorizer()
        return vectorizer.get_stats()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==================== æœç´¢API ====================

@app.post("/api/search/lines")
async def search_lines(request: SearchRequest):
    """æœç´¢å°è¯"""
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="æœç´¢æ¨¡å—æœªåŠ è½½")
    
    try:
        vectorizer = Vectorizer()
        results = vectorizer.search(
            query=request.query,
            n_results=request.limit,
            filters=request.filters
        )
        return {"results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/search/next-line")
async def search_next_line(request: NextLineRequest):
    """æœç´¢èƒ½æ¥çš„ä¸‹ä¸€å¥å°è¯"""
    if not ANNOTATION_AVAILABLE:
        raise HTTPException(status_code=503, detail="æœç´¢æ¨¡å—æœªåŠ è½½")
    
    try:
        vectorizer = Vectorizer()
        results = vectorizer.find_next_lines(
            current_line_id=request.current_line_id,
            n_results=request.limit
        )
        return {"results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# --- 4. å¯åŠ¨æœåŠ¡ ---
if __name__ == "__main__":
    # ä½¿ç”¨ 127.0.0.1 ç¡®ä¿æœ¬åœ°ç¨³å®šè®¿é—®
    uvicorn.run(app, host="127.0.0.1", port=8000)



    