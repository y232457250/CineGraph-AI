#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šä» JSON è¿ç§»åˆ° SQLite

åŠŸèƒ½ï¼š
1. åˆå§‹åŒ–æ–°çš„ SQLite æ•°æ®åº“
2. ä» media_index.json è¿ç§»å½±ç‰‡æ•°æ®
3. ä» annotations/ ç›®å½•è¿ç§»æ ‡æ³¨æ•°æ®
4. ä¿ç•™åŸæœ‰çš„ JSON æ–‡ä»¶ä½œä¸ºå¤‡ä»½

ä½¿ç”¨æ–¹æ³•ï¼š
    python backend/scripts/migrate_json_to_sqlite.py
"""

import json
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))


def migrate_movies(unified_store, json_store):
    """è¿ç§»å½±ç‰‡æ•°æ®"""
    print("\nğŸ“½ï¸  è¿ç§»å½±ç‰‡æ•°æ®...")
    
    movies = json_store.list_movies()
    print(f"   å‘ç° {len(movies)} ä¸ªå½±ç‰‡")
    
    migrated = 0
    failed = 0
    
    for movie in movies:
        try:
            # è½¬æ¢å­—æ®µåä»¥é€‚é…æ–°æ¨¡å‹
            movie_data = {
                'id': movie.get('douban_id') or movie.get('id'),
                'douban_id': movie.get('douban_id') or movie.get('id'),
                'title': movie.get('title', ''),
                'original_title': movie.get('original_title', ''),
                'year': movie.get('year'),
                'media_type': movie.get('media_type', 'movie'),
                'folder': movie.get('folder', ''),
                'poster_url': movie.get('poster_url', ''),
                'local_poster': movie.get('local_poster', ''),
                'director': movie.get('director', ''),
                'writer': movie.get('writer', ''),
                'starring': movie.get('starring', []),
                'genre': movie.get('genre', ''),
                'country': movie.get('country', ''),
                'language': movie.get('language', ''),
                'release_date': movie.get('release_date', ''),
                'douban_url': movie.get('douban_url', ''),
                'rating': movie.get('rating', ''),
                'crossover_genre': movie.get('crossover_genre', ''),
                'status': movie.get('status', 'pending'),
                'status_annotate': movie.get('status_annotate', 'pending'),
                'status_vectorize': movie.get('status_vectorize', 'pending'),
                'import_batch': movie.get('import_batch', ''),
                'episodes': movie.get('episodes', [])
            }
            
            unified_store.save_movie(movie_data)
            migrated += 1
            
            if migrated % 10 == 0:
                print(f"   å·²è¿ç§» {migrated}/{len(movies)}...")
                
        except Exception as e:
            print(f"   âŒ è¿ç§»å¤±è´¥ {movie.get('title', 'unknown')}: {e}")
            failed += 1
    
    print(f"   âœ… æˆåŠŸ: {migrated}, âŒ å¤±è´¥: {failed}")
    return migrated


def migrate_annotations(unified_store, annotations_dir):
    """è¿ç§»æ ‡æ³¨æ•°æ®"""
    print("\nğŸ“ è¿ç§»æ ‡æ³¨æ•°æ®...")
    
    if not annotations_dir.exists():
        print("   âš ï¸  æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return 0
    
    annotation_files = list(annotations_dir.glob("*_annotated.json"))
    print(f"   å‘ç° {len(annotation_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
    
    migrated = 0
    failed = 0
    
    for ann_file in annotation_files:
        try:
            # è§£ææ–‡ä»¶åè·å– movie_id å’Œ episode_number
            # æ ¼å¼: {movie_id}_ep{N}_annotated.json æˆ– {movie_id}_annotated.json
            filename = ann_file.stem  # å»æ‰ .json
            parts = filename.replace('_annotated', '').split('_ep')
            
            movie_id = parts[0]
            episode_number = int(parts[1]) if len(parts) > 1 else None
            
            # è¯»å–æ ‡æ³¨æ•°æ®
            with open(ann_file, 'r', encoding='utf-8') as f:
                annotations = json.load(f)
            
            # è¿ç§»åˆ°æ•°æ®åº“
            count = unified_store.save_annotations(movie_id, annotations, episode_number)
            migrated += count
            
            print(f"   âœ… {filename}: {count} æ¡æ ‡æ³¨")
            
        except Exception as e:
            print(f"   âŒ è¿ç§»å¤±è´¥ {ann_file.name}: {e}")
            failed += 1
    
    print(f"   âœ… æˆåŠŸè¿ç§» {migrated} æ¡æ ‡æ³¨, âŒ å¤±è´¥: {failed}")
    return migrated


def create_backup(data_dir):
    """åˆ›å»ºå¤‡ä»½"""
    print("\nğŸ’¾ åˆ›å»ºå¤‡ä»½...")
    
    backup_dir = data_dir / "backup" / f"pre_sqlite_migration_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    backup_dir.mkdir(parents=True, exist_ok=True)
    
    # å¤‡ä»½ media_index.json
    media_index = data_dir / "media_index.json"
    if media_index.exists():
        import shutil
        shutil.copy(media_index, backup_dir / "media_index.json")
        print(f"   âœ… å·²å¤‡ä»½ media_index.json")
    
    # å¤‡ä»½ annotations
    annotations_dir = data_dir / "annotations"
    if annotations_dir.exists():
        import shutil
        backup_annotations = backup_dir / "annotations"
        shutil.copytree(annotations_dir, backup_annotations)
        print(f"   âœ… å·²å¤‡ä»½ annotations/")
    
    print(f"   ğŸ“ å¤‡ä»½ä½ç½®: {backup_dir}")
    return backup_dir


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("CineGraph-AI æ•°æ®è¿ç§»å·¥å…·")
    print("JSON â†’ SQLite")
    print("=" * 60)
    
    # è·¯å¾„
    data_dir = backend_dir / "data"
    db_path = data_dir / "cinegraph.db"
    media_index_path = data_dir / "media_index.json"
    annotations_dir = data_dir / "annotations"
    
    # æ£€æŸ¥æºæ•°æ®
    if not media_index_path.exists():
        print("\nâŒ æœªæ‰¾åˆ° media_index.jsonï¼Œæ— æ³•è¿ç§»")
        return 1
    
    print(f"\nğŸ“ æ•°æ®ç›®å½•: {data_dir}")
    print(f"ğŸ¯ æ•°æ®åº“: {db_path}")
    print(f"ğŸ“„ å½±ç‰‡æ•°æ®: {media_index_path}")
    print(f"ğŸ“ æ ‡æ³¨æ•°æ®: {annotations_dir}")
    
    # ç¡®è®¤
    print("\nâš ï¸  æ­¤æ“ä½œå°†ï¼š")
    print("   1. åˆå§‹åŒ–æ–°çš„ SQLite æ•°æ®åº“")
    print("   2. ä» JSON å¯¼å…¥æ‰€æœ‰æ•°æ®")
    print("   3. åˆ›å»ºå¤‡ä»½ï¼ˆä¿ç•™åŸæ–‡ä»¶ï¼‰")
    print("\nåŸ JSON æ–‡ä»¶ä¸ä¼šè¢«åˆ é™¤ï¼Œå¯ä½œä¸ºå¤‡ä»½ã€‚")
    
    confirm = input("\næ˜¯å¦ç»§ç»­ï¼Ÿ(yes/no): ")
    if confirm.lower() != 'yes':
        print("å·²å–æ¶ˆ")
        return 0
    
    # åˆ›å»ºå¤‡ä»½
    backup_dir = create_backup(data_dir)
    
    # åˆå§‹åŒ–æ•°æ®åº“
    print("\nğŸ—„ï¸  åˆå§‹åŒ–æ•°æ®åº“...")
    from app.models.database import init_database
    
    config_path = backend_dir.parent / "config" / "mashup_v5_config.json"
    
    try:
        manager = init_database(str(db_path), str(config_path))
        print("   âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"   âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1
    
    # è·å–å­˜å‚¨å®ä¾‹
    from app.core.store import get_unified_store
    from app.core.store.json_store import JsonMovieStore
    
    unified_store = get_unified_store()
    json_store = JsonMovieStore(media_index_path)
    
    # è¿ç§»æ•°æ®
    movie_count = migrate_movies(unified_store, json_store)
    annotation_count = migrate_annotations(unified_store, annotations_dir)
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 60)
    print("è¿ç§»å®Œæˆï¼")
    print("=" * 60)
    print(f"\nâœ… å·²è¿ç§»:")
    print(f"   - å½±ç‰‡: {movie_count} ä¸ª")
    print(f"   - æ ‡æ³¨: {annotation_count} æ¡")
    print(f"\nğŸ’¾ å¤‡ä»½ä½ç½®: {backup_dir}")
    print(f"\nğŸ“ ä¸‹ä¸€æ­¥:")
    print("   1. é‡å¯åç«¯æœåŠ¡ï¼ˆå·²è‡ªåŠ¨ä½¿ç”¨ SQLiteï¼‰")
    print("   2. éªŒè¯æ•°æ®å®Œæ•´æ€§")
    print("   3. ç¡®è®¤æ— è¯¯åå¯åˆ é™¤å¤‡ä»½ï¼ˆå¯é€‰ï¼‰")
    print("=" * 60)
    
    return 0


if __name__ == "__main__":
    sys.exit(main() or 0)
