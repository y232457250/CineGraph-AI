#!/usr/bin/env python3
"""
æ ‡æ³¨æ–‡ä»¶æ ¼å¼è¿ç§»å·¥å…· v2.0
å°†æ—§æ ¼å¼çš„æ ‡æ³¨JSONè½¬æ¢ä¸ºæ–°çš„ç²¾ç®€è§„èŒƒæ ¼å¼

æ–°æ ¼å¼è§„èŒƒ (ç²¾ç®€ç‰ˆ):
{
  "id": "å¿ƒèŠ±è·¯æ”¾_line_042",
  "text": "ä½ æ•¢æ‰“æˆ‘",
  
  "source": {
    "media_id": "å¿ƒèŠ±è·¯æ”¾",      // å…³è”media_indexçš„key
    "start": 1234.5,
    "end": 1236.2
  },
  
  "mashup_tags": {
    "sentence_type": "åé—®",     // å…¨ä¸­æ–‡
    "emotion": "æ„¤æ€’",
    "tone": "æŒ‘è¡…",
    "primary_function": "åå·®èŒ",
    "style_effect": "åš£å¼ è·‹æ‰ˆ",
    "can_follow": ["å¨èƒ", "æŒ‘è¡…", "å‘½ä»¤"],
    "can_lead_to": ["åå‡»", "å®³æ€•", "å˜²è®½"],
    "keywords": ["æ‰“", "æ•¢"],
    "character_type": "å—å®³è€…"
  },
  
  "vector_text": "åé—® æ„¤æ€’ æŒ‘è¡… ä½ æ•¢æ‰“æˆ‘ åå‡» å˜²è®½ æ‰“ æ•¢",
  
  "editing_params": {
    "rhythm": "å¿«é€Ÿåˆ‡æ¢—",
    "duration": 1.7
  },
  
  "semantic_summary": "å—å®³è€…åå‡»çš„ç»å…¸å°è¯",
  "annotated_at": 1234567890.123
}
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List


# è‹±æ–‡â†’ä¸­æ–‡æ˜ å°„è¡¨
SENTENCE_TYPE_MAP = {
    "question": "é—®å¥", "answer": "ç­”å¥", "command": "å‘½ä»¤", "threat": "å¨èƒ",
    "counter_question": "åé—®", "mock": "å˜²è®½", "refuse": "æ‹’ç»", "fear": "å®³æ€•",
    "surrender": "æ±‚é¥¶", "counter_attack": "åå‡»", "anger": "æ„¤æ€’", "exclaim": "æ„Ÿå¹",
    "persuade": "åŠè¯´", "agree": "åŒæ„", "action": "è¡ŒåŠ¨", "interrupt": "æ‰“æ–­",
    "reveal": "æ­ç¤º", "obey": "æœä»", "comment": "è¯„è®º", "shock": "éœ‡æƒŠ"
}

EMOTION_MAP = {
    "angry": "æ„¤æ€’", "rage": "ç‹‚æ€’", "fear": "å®³æ€•", "mock": "å˜²è®½",
    "proud": "å¾—æ„", "arrogant": "åš£å¼ ", "helpless": "æ— å¥ˆ", "calm": "å†·é™",
    "shock": "éœ‡æƒŠ", "funny": "æç¬‘", "absurd": "è’è¯", "tsundere": "å‚²å¨‡"
}

TONE_MAP = {
    "strong": "å¼ºç¡¬", "weak": "è½¯å¼±", "provocative": "æŒ‘è¡…", "humble": "å‘å¾®",
    "arrogant": "å‚²æ…¢", "questioning": "è´¨ç–‘", "certain": "è‚¯å®š", "hesitant": "çŠ¹è±«",
    "pleading": "æ³æ±‚", "threatening": "å¨èƒ"
}

CHARACTER_TYPE_MAP = {
    "emperor": "çš‡å¸", "official": "å¤§è‡£", "hero": "è‹±é›„", "villain": "åæ´¾",
    "comic": "æç¬‘è§’è‰²", "victim": "å—å®³è€…", "bystander": "æ—è§‚è€…", "wise": "æ™ºè€…"
}


def to_chinese(value: str, mapping: Dict[str, str]) -> str:
    """å°†è‹±æ–‡æ ‡ç­¾è½¬æ¢ä¸ºä¸­æ–‡"""
    if not value:
        return value
    # å»é™¤å¯èƒ½çš„æ‹¬å·æ³¨é‡Šï¼Œå¦‚ "ç­”å¥(answer)" -> "ç­”å¥"
    clean_value = value.split("(")[0].strip()
    # å¦‚æœæ˜¯è‹±æ–‡keyï¼Œè½¬ä¸ºä¸­æ–‡
    if clean_value.lower() in mapping:
        return mapping[clean_value.lower()]
    # å¦‚æœå€¼æœ¬èº«å°±æ˜¯ä¸­æ–‡åç§°ï¼Œç›´æ¥è¿”å›
    if clean_value in mapping.values():
        return clean_value
    return clean_value


def migrate_annotation(old: Dict) -> Dict:
    """å°†æ—§æ ¼å¼æ ‡æ³¨è½¬æ¢ä¸ºæ–°çš„ç²¾ç®€æ ¼å¼"""
    
    # è®¡ç®—æ—¶é•¿
    start = old.get("start", 0)
    end = old.get("end", 0)
    duration = round(end - start, 2) if end > start else 0
    
    # è·å–media_id (ä»sourceæˆ–æ—§å­—æ®µ)
    source = old.get("source", {})
    media_id = source.get("media_id") or source.get("movie_id") or old.get("source_movie", "")
    if not start and source:
        start = source.get("start", 0)
        end = source.get("end", 0)
        duration = round(end - start, 2) if end > start else 0
    
    # è·å–mashup_tags (ä»åµŒå¥—æˆ–æ—§å­—æ®µ)
    tags = old.get("mashup_tags", {})
    
    # è‹±æ–‡â†’ä¸­æ–‡è½¬æ¢
    sentence_type = to_chinese(
        tags.get("sentence_type") or old.get("sentence_type", ""), 
        SENTENCE_TYPE_MAP
    )
    emotion = to_chinese(
        tags.get("emotion") or old.get("emotion", ""), 
        EMOTION_MAP
    )
    tone = to_chinese(
        tags.get("tone") or old.get("tone", ""), 
        TONE_MAP
    )
    character_type = to_chinese(
        tags.get("character_type") or old.get("character_type", ""), 
        CHARACTER_TYPE_MAP
    )
    
    # can_follow/can_lead_to ä¹Ÿè½¬ä¸­æ–‡
    can_follow_raw = tags.get("can_follow") or old.get("can_follow", [])
    can_lead_to_raw = tags.get("can_lead_to") or old.get("can_lead_to", [])
    can_follow = [to_chinese(t, SENTENCE_TYPE_MAP) for t in can_follow_raw]
    can_lead_to = [to_chinese(t, SENTENCE_TYPE_MAP) for t in can_lead_to_raw]
    
    # è·å–å…¶ä»–å­—æ®µ
    keywords = tags.get("keywords") or old.get("keywords", [])
    primary_function = tags.get("primary_function") or old.get("primary_function", "")
    style_effect = tags.get("style_effect") or old.get("style_effect", "")
    
    # è·å–å‰ªè¾‘å‚æ•°
    editing = old.get("editing_params", {})
    rhythm = editing.get("rhythm") or old.get("editing_rhythm", "")
    
    # æ„å»ºæ–°æ ¼å¼ (ç²¾ç®€ç‰ˆ)
    new = {
        "id": old.get("id", ""),
        "text": old.get("text", ""),
        
        # ğŸ“ æ¥æºå®šä½ (ç²¾ç®€)
        "source": {
            "media_id": media_id,
            "start": start,
            "end": end
        },
        
        # ğŸ­ æ··å‰ªæ ¸å¿ƒæ ‡ç­¾ (å…¨ä¸­æ–‡)
        "mashup_tags": {
            "sentence_type": sentence_type,
            "emotion": emotion,
            "tone": tone,
            "primary_function": primary_function,
            "style_effect": style_effect,
            "can_follow": can_follow,
            "can_lead_to": can_lead_to,
            "keywords": keywords,
            "character_type": character_type
        },
        
        # ğŸ” å‘é‡åŒ–æ–‡æœ¬ (çº¯ä¸­æ–‡)
        "vector_text": generate_vector_text_v2(
            sentence_type, emotion, tone, 
            old.get("text", ""), 
            can_lead_to, keywords
        ),
        
        # ğŸ“Š å‰ªè¾‘å‚æ•° (ç²¾ç®€)
        "editing_params": {
            "rhythm": rhythm,
            "duration": duration
        },
        
        # è¯­ä¹‰æ‘˜è¦
        "semantic_summary": old.get("semantic_summary", ""),
        
        # æ—¶é—´æˆ³
        "annotated_at": old.get("annotated_at", 0)
    }
    
    return new


def generate_vector_text_v2(
    sentence_type: str, emotion: str, tone: str,
    text: str, can_lead_to: List[str], keywords: List[str]
) -> str:
    """ç”Ÿæˆçº¯ä¸­æ–‡çš„å‘é‡åŒ–æ–‡æœ¬"""
    parts = [sentence_type, emotion, tone, text]
    
    if can_lead_to:
        parts.extend(can_lead_to)
    
    if keywords:
        parts.extend(keywords)
    
    return " ".join(filter(None, parts))


def migrate_file(input_path: str, output_path: str = None) -> int:
    """è¿ç§»å•ä¸ªæ ‡æ³¨æ–‡ä»¶"""
    
    input_path = Path(input_path)
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return 0
    
    # åŠ è½½æ—§æ•°æ®
    with open(input_path, "r", encoding="utf-8") as f:
        old_data = json.load(f)
    
    if not isinstance(old_data, list):
        print(f"âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯: æœŸæœ›åˆ—è¡¨ï¼Œå¾—åˆ° {type(old_data)}")
        return 0
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ–°çš„ç²¾ç®€æ ¼å¼
    if old_data:
        first = old_data[0]
        source = first.get("source", {})
        # æ–°ç²¾ç®€æ ¼å¼: sourceåªæœ‰media_id, start, end
        is_new_format = (
            "source" in first and 
            "mashup_tags" in first and
            "media_id" in source and
            "movie_id" not in source and
            "subtitle_file" not in source
        )
        if is_new_format:
            print(f"â„¹ï¸ æ–‡ä»¶å·²ç»æ˜¯ç²¾ç®€æ ¼å¼: {input_path}")
            return 0
    
    # è½¬æ¢
    new_data = [migrate_annotation(ann) for ann in old_data]
    
    # è¾“å‡ºè·¯å¾„
    if output_path is None:
        output_path = input_path.parent / f"{input_path.stem}_migrated.json"
    else:
        output_path = Path(output_path)
    
    # ä¿å­˜
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(new_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… è¿ç§»å®Œæˆ: {input_path} -> {output_path}")
    print(f"   å…± {len(new_data)} æ¡æ ‡æ³¨")
    
    return len(new_data)


def migrate_directory(dir_path: str, in_place: bool = False) -> int:
    """è¿ç§»ç›®å½•ä¸‹æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶"""
    
    dir_path = Path(dir_path)
    if not dir_path.is_dir():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dir_path}")
        return 0
    
    total = 0
    json_files = list(dir_path.glob("*_annotated.json"))
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(json_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
    
    for f in json_files:
        if "_migrated" in f.name:
            continue
        
        output_path = f if in_place else None
        count = migrate_file(str(f), output_path)
        total += count
    
    return total


def main():
    parser = argparse.ArgumentParser(description="æ ‡æ³¨æ–‡ä»¶æ ¼å¼è¿ç§»å·¥å…·")
    parser.add_argument("input", help="è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„")
    parser.add_argument("-o", "--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä»…ç”¨äºå•æ–‡ä»¶è¿ç§»ï¼‰")
    parser.add_argument("--in-place", action="store_true", help="åŸåœ°æ›´æ–°æ–‡ä»¶ï¼ˆç›®å½•è¿ç§»æ—¶ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="ä»…æ£€æŸ¥ï¼Œä¸å®é™…è¿ç§»")
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ”„ æ ‡æ³¨æ–‡ä»¶æ ¼å¼è¿ç§»å·¥å…·")
    print("=" * 60)
    
    input_path = Path(args.input)
    
    if args.dry_run:
        print("ğŸ” å¹²è¿è¡Œæ¨¡å¼ - ä»…æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
        if input_path.is_file():
            with open(input_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            if data and "source" in data[0] and "mashup_tags" in data[0]:
                print(f"âœ… {input_path} å·²æ˜¯æ–°æ ¼å¼")
            else:
                print(f"âš ï¸ {input_path} éœ€è¦è¿ç§»")
        return
    
    if input_path.is_file():
        migrate_file(str(input_path), args.output)
    elif input_path.is_dir():
        total = migrate_directory(str(input_path), args.in_place)
        print(f"\nğŸ“Š æ€»å…±è¿ç§» {total} æ¡æ ‡æ³¨")
    else:
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_path}")


if __name__ == "__main__":
    main()
