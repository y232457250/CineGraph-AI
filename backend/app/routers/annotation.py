"""
è¯­ä¹‰æ ‡æ³¨è·¯ç”± - å¤„ç† LLM æ ‡æ³¨ä»»åŠ¡
"""
from fastapi import APIRouter, HTTPException, BackgroundTasks
from pathlib import Path
import os
import threading
import json

from app.ingestion.semantic_annotator import SemanticAnnotator, LLMProviderManager

router = APIRouter(prefix="/api/annotation", tags=["annotation"])

# å…¨å±€çŠ¶æ€
annotation_status = {
    "running": False,
    "progress": 0,
    "total": 0,
    "current_movie": "",
    "error": None
}
annotation_cancel_event = threading.Event()


class AnnotateRequest:
    def __init__(self, **kwargs):
        self.movie_id = kwargs.get("movie_id")
        self.subtitle_path = kwargs.get("subtitle_path")
        self.movie_name = kwargs.get("movie_name", "")
        self.llm_provider = kwargs.get("llm_provider")
        self.batch_size = kwargs.get("batch_size")
        self.concurrent_requests = kwargs.get("concurrent_requests")
        self.max_retries = kwargs.get("max_retries")
        self.save_interval = kwargs.get("save_interval")


@router.get("/providers")
async def list_llm_providers():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„LLMæä¾›è€…"""
    try:
        manager = LLMProviderManager()
        return {"providers": manager.list_providers()}
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"è¯­ä¹‰æ ‡æ³¨æ¨¡å—æœªåŠ è½½: {e}")


@router.post("/test-connection")
async def test_llm_connection(request: dict):
    """æµ‹è¯•LLMè¿æ¥"""
    try:
        provider_id = request.get("provider_id")
        if not provider_id:
            return {"success": False, "error": "æœªæŒ‡å®šæ¨¡å‹ID"}
        
        manager = LLMProviderManager()
        provider = manager.get_provider(provider_id)
        
        if not provider:
            return {"success": False, "error": f"æœªæ‰¾åˆ°æ¨¡å‹: {provider_id}"}
        
        result = provider.test_connection()
        return result
    except Exception as e:
        return {"success": False, "error": f"æµ‹è¯•å¤±è´¥: {str(e)}"}


@router.post("/start")
async def start_annotation(request: dict, background_tasks: BackgroundTasks):
    """å¼€å§‹å¯¹å­—å¹•æ–‡ä»¶è¿›è¡Œè¯­ä¹‰æ ‡æ³¨"""
    global annotation_status
    
    if annotation_status["running"]:
        raise HTTPException(status_code=409, detail="æ ‡æ³¨ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­")
    
    subtitle_path = request.get("subtitle_path")
    if not subtitle_path or not os.path.exists(subtitle_path):
        raise HTTPException(status_code=400, detail=f"å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {subtitle_path}")
    
    annotation_cancel_event.clear()
    background_tasks.add_task(
        run_annotation,
        request.get("movie_id"),
        subtitle_path,
        request.get("movie_name") or request.get("movie_id"),
        request.get("llm_provider"),
        request.get("batch_size"),
        request.get("concurrent_requests"),
        request.get("max_retries"),
        request.get("save_interval")
    )
    
    return {"status": "started", "movie_id": request.get("movie_id")}


def run_annotation(
    movie_id: str, 
    subtitle_path: str, 
    movie_name: str, 
    llm_provider: str = None,
    batch_size: int = None,
    concurrent_requests: int = None,
    max_retries: int = None,
    save_interval: int = None
):
    """åå°æ‰§è¡Œè¯­ä¹‰æ ‡æ³¨"""
    global annotation_status
    
    annotation_status = {
        "running": True,
        "progress": 0,
        "total": 0,
        "current_movie": movie_name,
        "error": None
    }
    
    try:
        annotator = SemanticAnnotator(
            llm_provider=llm_provider,
            max_retries=max_retries,
            save_interval=save_interval
        )
        
        def progress_callback(current, total):
            annotation_status["progress"] = current
            annotation_status["total"] = total
        
        print(f"ğŸ“‹ æ ‡æ³¨å‚æ•°: batch_size={batch_size}, concurrent={concurrent_requests}")
        
        annotations = annotator.annotate_subtitle_file(
            subtitle_path=subtitle_path,
            movie_name=movie_name,
            movie_id=movie_id,
            window_size=5,
            max_workers=concurrent_requests,
            batch_size=batch_size,
            progress_callback=progress_callback,
            cancel_event=annotation_cancel_event
        )
        
        if annotation_cancel_event.is_set():
            annotation_status["running"] = False
            annotation_status["current_movie"] = "å·²å–æ¶ˆï¼ˆæœªä¿å­˜å½“å‰æ–‡ä»¶ï¼‰"
            annotation_status["error"] = "å·²å–æ¶ˆ"
            return
        
        if annotations and len(annotations) > 0:
            output_dir = Path(__file__).parent.parent.parent / "data" / "annotations"
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = output_dir / f"{movie_id}_annotated.json"
            
            annotator.save_annotations(annotations, str(output_path))
            print(f"âœ… æ ‡æ³¨å·²ä¿å­˜: {output_path}")
        
        annotation_status["running"] = False
        annotation_status["progress"] = annotation_status["total"]
        
    except Exception as e:
        annotation_status["running"] = False
        annotation_status["error"] = str(e)
        print(f"âŒ æ ‡æ³¨å¤±è´¥: {e}")


@router.get("/status")
async def get_annotation_status():
    """è·å–æ ‡æ³¨è¿›åº¦"""
    return annotation_status


@router.post("/cancel")
async def cancel_annotation():
    """å–æ¶ˆå½“å‰æ ‡æ³¨ä»»åŠ¡"""
    annotation_cancel_event.set()
    annotation_status["running"] = False
    annotation_status["error"] = "å·²å–æ¶ˆ"
    return {"success": True}


@router.get("/list")
async def list_annotations():
    """åˆ—å‡ºæ‰€æœ‰å·²æ ‡æ³¨çš„æ–‡ä»¶"""
    output_dir = Path(__file__).parent.parent.parent / "data" / "annotations"
    if not output_dir.exists():
        return {"annotations": []}
    
    annotations = []
    for f in output_dir.glob("*_annotated.json"):
        try:
            with open(f, "r", encoding="utf-8") as file:
                data = json.load(file)
            annotations.append({
                "file": str(f),
                "movie_id": f.stem.replace("_annotated", ""),
                "line_count": len(data),
                "size": f.stat().st_size
            })
        except Exception:
            continue
    
    return {"annotations": annotations}
