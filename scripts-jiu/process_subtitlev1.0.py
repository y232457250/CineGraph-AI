# scripts-jiu/process_subtitle.py
import os
import re
import json
import argparse
import time
import sys
from typing import List, Dict
from pathlib import Path
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==================== é…ç½® ====================
LLM_API = "http://localhost:8001/v1/completions"
CONFIG_PATH = r"D:\AI\CineGraph-AI\config\theme_config.json"

# å®Œæ•´çš„é»˜è®¤é…ç½®ï¼ˆåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µï¼‰
DEFAULT_CONFIG = {
    "version": "v1.0",
    "emotions": ["å–œæ‚¦", "æ„¤æ€’", "æ‚²ä¼¤", "ææƒ§", "æƒŠè®¶", "è®½åˆº", "å¹½é»˜", "ä¸­æ€§"],
    "themes": [
        "èº«ä»½é”™ä½", "è¯­è¨€è’è¯", "ç”Ÿå­˜åè½¬", "æ–‡åŒ–ç©æ¢—", 
        "æƒ…æ„Ÿåè½¬", "å…³ç³»è¯•æ¢", "æƒåŠ›åšå¼ˆ", "å…¶ä»–"
    ],
    "priority_emotions": ["è®½åˆº", "å¹½é»˜"]
}

def load_semantic_config() -> dict:
    """å®‰å…¨åŠ è½½é…ç½®ï¼Œç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨"""
    config = DEFAULT_CONFIG.copy()  # ä»¥é»˜è®¤é…ç½®ä¸ºåŸºç¡€
    
    if os.path.exists(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                user_config = json.load(f)
            
            # ä»…æ›´æ–°å­˜åœ¨çš„å­—æ®µï¼Œä¿ç•™é»˜è®¤é…ç½®ä¸­ç¼ºå¤±å­—æ®µçš„é»˜è®¤å€¼
            for key in ["version", "emotions", "themes", "priority_emotions"]:
                if key in user_config and user_config[key]:
                    config[key] = user_config[key]
            
            print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {CONFIG_PATH}")
            print(f"   æƒ…ç»ªåˆ—è¡¨: {', '.join(config['emotions'][:3])}...")
            print(f"   ä¸»é¢˜åˆ—è¡¨: {', '.join(config['themes'][:3])}...")
        except Exception as e:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶è§£æå¤±è´¥ ({e})ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ {CONFIG_PATH}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    # éªŒè¯å¿…éœ€å­—æ®µ
    required_fields = ["version", "emotions", "themes", "priority_emotions"]
    for field in required_fields:
        if field not in config or not config[field]:
            raise ValueError(f"é…ç½®ç¼ºå¤±å¿…éœ€å­—æ®µ: {field}")
    
    return config

# å®‰å…¨åŠ è½½é…ç½®ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
try:
    SEMANTIC_CONFIG = load_semantic_config()
    EMOTIONS = SEMANTIC_CONFIG["emotions"]
    THEMES = SEMANTIC_CONFIG["themes"]
    PRIORITY_EMOTIONS = SEMANTIC_CONFIG["priority_emotions"]
    CONFIG_VERSION = SEMANTIC_CONFIG["version"]
except Exception as e:
    print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
    print("è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼æˆ–ä½¿ç”¨é»˜è®¤é…ç½®")
    sys.exit(1)

# ==================== æ„å»ºæç¤ºè¯ ====================
def build_prompt(current_line: str, context_lines: List[str]) -> str:
    emotions_str = json.dumps(EMOTIONS, ensure_ascii=False)
    themes_str = json.dumps(THEMES, ensure_ascii=False)
    priority_str = "ã€".join(PRIORITY_EMOTIONS)
    
    return (
        "ä½ æ˜¯ä¸€ä½å½±è§†æ··å‰ªè¯­ä¹‰åˆ†æä¸“å®¶ï¼Œä¸“ç²¾å°å“/ç›¸å£°/è„±å£ç§€çš„ç½‘ç»œçƒ­æ¢—ã€‚"
        "è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹è¦æ±‚è¾“å‡ºçº¯JSONï¼Œç¦æ­¢ä»»ä½•é¢å¤–æ–‡å­—ã€è§£é‡Šã€Markdownã€æ³¨é‡Šæˆ–å‰§æƒ…æè¿°ã€‚"
        "è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼çš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼ˆåŒ…æ‹¬ä»£ç å—æ ‡è®°ï¼‰ã€‚"
        "ç¡®ä¿JSONåŒ…å«ä»¥ä¸‹ä¸‰ä¸ªå¿…éœ€å­—æ®µï¼šline_annotation, context_annotation, config_versionã€‚"
        
        "ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘"
        "{"
        '  "line_annotation": {'
        '    "emotion": "æƒ…æ„Ÿ",'
        '    "theme": "ä¸»é¢˜",'
        '    "subtext": "å®åˆ™å¼€å¤´çš„50å­—å†…åˆ†æ"'
        '  },'
        '  "context_annotation": {'
        '    "emotion": "æƒ…æ„Ÿ",'
        '    "theme": "ä¸»é¢˜",'
        '    "subtext": "50å­—å†…ç›´æ¥æè¿°"'
        '  },'
        f'  "config_version": "{CONFIG_VERSION}"'
        "}"
        
        "ã€å­—æ®µè§„åˆ™ã€‘"
        "â–¶ line_annotationï¼ˆå½“å‰å°è¯ï¼‰ï¼š"
        f"- emotion: ä»åˆ—è¡¨ä¸­é€‰1é¡¹ï¼š{emotions_str}ï¼ˆä¼˜å…ˆè€ƒè™‘ï¼š{priority_str}ï¼‰"
        f"- theme: ä»åˆ—è¡¨ä¸­é€‰1é¡¹æˆ–ç»„åˆæˆ4-8å­—åŠ¨è¯çŸ­è¯­ï¼š{themes_str}ï¼Œå¿…é¡»ä½“ç°åŠ¨ä½œæ€§"
        "- subtext: 50å­—å†…ï¼Œç†è§£å½“å‰æ–‡å­—ï¼Œç›´å‡»çœŸå®æ„å›¾ï¼Œç¦æ­¢'å®åˆ™''å› ä¸º''ç”±äº''çœ‹å‡ºæ¥äº†'ç­‰è¯ï¼Œç¦æ­¢æ‹¬å·ã€çœç•¥å·ã€å ä½è¯´æ˜"
        
        "â–¶ context_annotationï¼ˆå¯¹è¯ç‰‡æ®µï¼‰ï¼š"
        f"- emotion: ä»åˆ—è¡¨ä¸­é€‰1é¡¹ï¼š{emotions_str}"
        f"- theme: ä»åˆ—è¡¨ä¸­é€‰1é¡¹æˆ–ç»„åˆæˆ4-8å­—åŠ¨è¯çŸ­è¯­ï¼š{themes_str}"
        "- subtext: 50å­—å†…ï¼Œç›´æ¥æè¿°åŒæ–¹äº’åŠ¨çœŸå®ç›®çš„ï¼Œç¦æ­¢'å®åˆ™''çœ‹å‡ºæ¥äº†'ã€'å› ä¸º'ã€æ‹¬å·ã€çœç•¥å·ã€å ä½æ–‡å­—"
        
        "ã€å¼ºåˆ¶è§„åˆ™ã€‘"
        "1. èº«ä»½é”™ä½å°è¯ â†’ theme='èº«ä»½é”™ä½'"
        "2. è¯­è¨€é‡å¤å°è¯ â†’ theme='è¯­è¨€è’è¯'"
        "3. æ— åè½¬å°è¯ â†’ emotion='ä¸­æ€§', subtext='æ— æ˜æ˜¾åè½¬'"
        "4. æ‰€æœ‰subtextå­—æ®µå¿…é¡»æ˜¯å®Œæ•´å¥å­ï¼Œä¸å¾—åŒ…å«'...'ã€'ï¼ˆ50å­—å†…ï¼‰'ç­‰å ä½ç¬¦"
        "5. ä¸»é¢˜å¿…é¡»ä½“ç°åŠ¨ä½œæ€§ï¼ˆå¦‚'åˆ¶é€ è¯¯ä¼š'âœ…ï¼Œè€Œé'è¯¯ä¼š'âŒï¼‰"
        
        "ã€å¾…åˆ†æå†…å®¹ã€‘"
        f"å½“å‰å°è¯ï¼š'{current_line}'"
        f"ä¸Šä¸‹æ–‡ç‰‡æ®µï¼š{json.dumps(context_lines, ensure_ascii=False)}"
    )

# ==================== å­—å¹•è§£æ ====================
def parse_srt(file_path: str) -> List[Dict]:
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        content = f.read()
    
    blocks = re.split(r"\n\s*\n", content.strip())
    lines = []
    for block in blocks:
        parts = block.strip().split("\n")
        if len(parts) < 3:
            continue
        try:
            time_range = parts[1]
            text = " ".join(parts[2:]).replace("\n", " ").strip()
            if not text or "-->" not in time_range:
                continue
            start_str, end_str = time_range.split(" --> ")
            start = _time_to_seconds(start_str)
            end = _time_to_seconds(end_str)
            lines.append({
                "text": text,
                "start": start,
                "end": end
            })
        except Exception as e:
            continue  # è·³è¿‡è§£æå¤±è´¥çš„å—
    return lines

def _time_to_seconds(time_str: str) -> float:
    h, m, s_ms = time_str.replace(",", ".").split(":")
    return float(h) * 3600 + float(m) * 60 + float(s_ms)

# ==================== JSONè§£æä¸éªŒè¯ ====================
def parse_llm_response(response_text: str) -> dict:
    """ä¸¥æ ¼éªŒè¯å¹¶ä¿®å¤LLMè¿”å›çš„JSON"""
    # ç§»é™¤Markdownæ ‡è®°
    response_text = re.sub(r'```(?:json)?|```', '', response_text).strip()
    
    # ç¡®ä¿JSONç»“æ„å®Œæ•´
    if not response_text.startswith('{'):
        response_text = '{' + response_text
    if not response_text.endswith('}'):
        response_text = response_text + '}'
    
    try:
        parsed = json.loads(response_text)
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required = ["line_annotation", "context_annotation", "config_version"]
        for field in required:
            if field not in parsed:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # éªŒè¯åµŒå¥—ç»“æ„
        for key in ["line_annotation", "context_annotation"]:
            if not isinstance(parsed[key], dict):
                raise ValueError(f"{key} å¿…é¡»æ˜¯å¯¹è±¡")
            for subkey in ["emotion", "theme", "subtext"]:
                if subkey not in parsed[key]:
                    raise ValueError(f"ç¼ºå°‘å­å­—æ®µ: {key}.{subkey}")
        
        return parsed
    except Exception as e:
        # å®‰å…¨å›é€€æ–¹æ¡ˆ
        return {
            "line_annotation": {
                "emotion": "ä¸­æ€§",
                "theme": "å…¶ä»–",
                "subtext": "æ— æ˜æ˜¾åè½¬"
            },
            "context_annotation": {
                "emotion": "ä¸­æ€§",
                "theme": "å…¶ä»–",
                "subtext": "æ— æ˜æ˜¾äº’åŠ¨æ„å›¾"
            },
            "config_version": CONFIG_VERSION
        }

# ==================== è¯­ä¹‰æ ‡æ³¨ ====================
def annotate_with_context(current_line: str, context_lines: List[str], max_retries=2) -> Dict:
    prompt = build_prompt(current_line, context_lines)
    
    for attempt in range(max_retries):
        try:
            response = requests.post(
                LLM_API,
                json={
                    "model": "qwen3-chat",
                    "prompt": prompt,
                    "max_tokens": 250,
                    "temperature": 0.1,
                    "response_format": {"type": "json_object"}
                },
                timeout=25,
                headers={"Content-Type": "application/json"}
            )
            response.raise_for_status()
            result = response.json()
            content = result["choices"][0]["text"].strip()
            
            parsed = parse_llm_response(content)
            
            # éªŒè¯emotionå’Œthemeåœ¨å…è®¸åˆ—è¡¨ä¸­ï¼ˆå®½æ¾éªŒè¯ï¼‰
            if parsed["line_annotation"]["emotion"] not in EMOTIONS:
                parsed["line_annotation"]["emotion"] = "ä¸­æ€§"
            if parsed["line_annotation"]["theme"] not in THEMES:
                parsed["line_annotation"]["theme"] = "å…¶ä»–"
            
            return parsed
        except Exception as e:
            if attempt == max_retries - 1:
                return parse_llm_response("")  # è§¦å‘å›é€€æ–¹æ¡ˆ
            time.sleep(0.5)  # çŸ­æš‚ç­‰å¾…åé‡è¯•

# ==================== å•è¡Œå¤„ç†å‡½æ•° ====================
def process_single_line(line_data, idx, total, window_size, all_lines):
    line = line_data
    start_idx = max(0, idx - window_size)
    end_idx = min(total, idx + window_size + 1)
    context_texts = [all_lines[j]["text"] for j in range(start_idx, end_idx)]
    
    result = annotate_with_context(line["text"], context_texts)
    
    return {
        "id": f"line_{idx}",
        "text": line["text"],
        "start": line["start"],
        "end": line["end"],
        "emotion": result["line_annotation"]["emotion"],
        "theme": result["line_annotation"]["theme"],
        "subtext": result["line_annotation"]["subtext"],
        "dialogue_context": {
            "emotion": result["context_annotation"]["emotion"],
            "theme": result["context_annotation"]["theme"],
            "subtext": result["context_annotation"]["subtext"]
        },
        "config_version": result.get("config_version", CONFIG_VERSION)
    }

# ==================== ä¸»å¤„ç†æµç¨‹ ====================
def process_srt(input_path: str, output_dir: str, window_size: int = 1, max_workers: int = 4):
    print(f"ğŸ” è§£æå­—å¹•æ–‡ä»¶: {input_path}")
    lines = parse_srt(input_path)
    if not lines:
        print("âŒ æœªè§£æåˆ°æœ‰æ•ˆå­—å¹•è¡Œï¼Œè¯·æ£€æŸ¥å­—å¹•æ–‡ä»¶æ ¼å¼")
        return
    
    total = len(lines)
    print(f"âœ… æˆåŠŸè§£æ {total} è¡Œå­—å¹•")
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† (çº¿ç¨‹æ•°: {max_workers}, çª—å£å¤§å°: {window_size})...")
    
    annotated_lines = [None] * total  # é¢„åˆ†é…åˆ—è¡¨ä¿æŒé¡ºåº
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(process_single_line, lines[i], i, total, window_size, lines): i
            for i in range(total)
        }
        
        completed = 0
        for future in as_completed(futures):
            idx = futures[future]
            try:
                result = future.result()
                annotated_lines[idx] = result
                completed += 1
                
                # æ¯10%æˆ–æœ€å10è¡Œæ˜¾ç¤ºè¿›åº¦
                if completed % max(1, total // 10) == 0 or completed >= total - 5:
                    elapsed = time.time() - start_time
                    progress = completed / total
                    eta = (elapsed / progress - elapsed) if progress > 0 else 0
                    speed = completed / elapsed if elapsed > 0 else 0
                    print(f"ğŸ”„ [{completed}/{total}] {progress:.0%} | é€Ÿåº¦: {speed:.1f}è¡Œ/ç§’ | ETA: {eta:.0f}s | '{result['text'][:25]}...'")
            except Exception as e:
                print(f"âŒ å¤„ç†ç¬¬ {idx} è¡Œæ—¶å‡ºé”™: {e}")
                # å®‰å…¨å›é€€
                annotated_lines[idx] = {
                    "id": f"line_{idx}",
                    "text": lines[idx]["text"],
                    "start": lines[idx]["start"],
                    "end": lines[idx]["end"],
                    "emotion": "ä¸­æ€§",
                    "theme": "å…¶ä»–",
                    "subtext": "å¤„ç†å¤±è´¥",
                    "dialogue_context": {
                        "emotion": "ä¸­æ€§",
                        "theme": "å…¶ä»–",
                        "subtext": "å¤„ç†å¤±è´¥"
                    },
                    "config_version": CONFIG_VERSION
                }
    
    # è¿‡æ»¤Noneå€¼ï¼ˆç†è®ºä¸Šä¸åº”æœ‰ï¼‰
    annotated_lines = [line for line in annotated_lines if line is not None]
    
    # ä¿å­˜ç»“æœ
    base_name = Path(input_path).stem
    output_path = Path(output_dir) / f"{base_name}_annotated.json"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(annotated_lines, f, ensure_ascii=False, indent=2)
    
    total_time = time.time() - start_time
    print("\n" + "="*50)
    print(f"âœ… å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š æ€»è¡Œæ•°: {total} | è€—æ—¶: {total_time:.1f}ç§’ | å¹³å‡é€Ÿåº¦: {total/total_time:.1f}è¡Œ/ç§’")
    print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")
    print(f"ğŸ“Œ é…ç½®ç‰ˆæœ¬: {CONFIG_VERSION}")
    print("="*50)

# ==================== CLI å…¥å£ ====================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="ğŸš€ å½±è§†å­—å¹•å¤šç»´è¯­ä¹‰æ ‡æ³¨å·¥å…·ï¼ˆå¤šçº¿ç¨‹åŠ é€Ÿç‰ˆï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python process_subtitle.py "D:/AI/CineGraph-AI/data/media/subtitles/test.srt" "D:/AI/CineGraph-AI/data/analysis" --workers 6
        """
    )
    parser.add_argument("input", help="è¾“å…¥ .srt å­—å¹•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("output_dir", help="è¾“å‡º JSON ç›®å½•")
    parser.add_argument("--window", type=int, default=1, help="ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆé»˜è®¤: 1ï¼‰")
    parser.add_argument("--workers", type=int, default=4, help="å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°ï¼ˆå»ºè®®: 4-8ï¼‰")
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    # éªŒè¯APIè¿æ¥
    try:
        requests.get(LLM_API.replace("/v1/completions", "/health"), timeout=3)
        print(f"âœ… LLM API æœåŠ¡æ­£å¸¸: {LLM_API}")
    except:
        print(f"âš ï¸  LLM API æœåŠ¡å¯èƒ½æœªå¯åŠ¨: {LLM_API}")
        print("   è¯·ç¡®ä¿ Qwen3-Chat æœåŠ¡å·²é€šè¿‡ Docker å¯åŠ¨")
        # ä¸ä¸­æ–­ï¼Œç»§ç»­å¤„ç†ï¼ˆä¼šä½¿ç”¨å›é€€æ–¹æ¡ˆï¼‰
    
    process_srt(args.input, args.output_dir, args.window, args.workers)