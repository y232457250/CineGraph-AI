# scripts-jiu/process_subtitle_enhanced.py
import os
import re
import json
import argparse
import time
import sys
from typing import List, Dict, Tuple
from pathlib import Path
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==================== é…ç½® ====================
LLM_API = "http://localhost:8001/v1/completions"
CONFIG_PATH = r"D:\AI\CineGraph-AI\config\mashup_config.json"

# æ··å‰ªä¸“ç”¨æ ‡ç­¾ä½“ç³»
DEFAULT_MASHUP_CONFIG = {
    "version": "v3.0-mashup-pro",
    
    # æ··å‰ªæ ¸å¿ƒåŠŸèƒ½æ ‡ç­¾ï¼ˆè¿™æ®µå°è¯åœ¨æ··å‰ªä¸­èƒ½åšä»€ä¹ˆï¼‰
    "mashup_functions": [
        "æŠ›æ¢—å¼€åœº", "èº«ä»½åè½¬", "åœºæ™¯å«æ¥", "é‡‘å¥å¼•ç”¨", 
        "è·¨æœèŠå¤©", "å¼ºè¡Œè§£é‡Š", "åå·®èŒ", "ååœºé¢å†ç°",
        "ä¸€æœ¬æ­£ç»èƒ¡è¯´", "é™ç»´æ‰“å‡»", "æ—¶ä»£é”™ä½", "æ¬¡å…ƒçªç ´",
        "ç¥è½¬æŠ˜", "åºŸè¯æ–‡å­¦", "æ— æ•ˆæ²Ÿé€š", "è‡ªè¯´è‡ªè¯",
        "èœœæ±è‡ªä¿¡", "å¼±å°å¯æ€œ", "åš£å¼ è·‹æ‰ˆ", "é˜´é˜³æ€ªæ°”"
    ],
    
    # å‰ªè¾‘èŠ‚å¥æ ‡ç­¾ï¼ˆè¿™æ®µå°è¯æ€ä¹ˆå‰ªï¼‰
    "editing_rhythms": [
        "å¿«é€Ÿåˆ‡æ¢—", "æ…¢æ”¾æ‰“è„¸", "é‡å¤é¬¼ç•œ", "æˆ›ç„¶è€Œæ­¢",
        "é€’è¿›å¤¸å¼ ", "çªç„¶æ‰“æ–­", "ç”»å¤–éŸ³æ€¼", "ç”»é¢ç¥é…",
        "éŸ³æ•ˆé…åˆ", "å˜é€Ÿå¤„ç†", "é‡å¤å¼ºè°ƒ", "é™éŸ³åå·®"
    ],
    
    # æç¬‘æ•ˆæœæ ‡ç­¾ï¼ˆä¼šäº§ç”Ÿä»€ä¹ˆç¬‘ç‚¹ï¼‰
    "humor_effects": [
        "æ— å˜å¤´æç¬‘", "å°´å°¬å†·åœº", "å‚²å¨‡å£å«Œ", "éœ‡æƒŠå…¨å®¶",
        "èœœæ±è‡ªä¿¡", "å¼±å°æ— åŠ©", "åš£å¼ è·‹æ‰ˆ", "é˜´é˜³æ€ªæ°”",
        "ä¸€æœ¬æ­£ç»", "é™æ™ºæ‰“å‡»", "å¼ºè¡Œåˆç†", "é€»è¾‘é¬¼æ‰"
    ],
    
    # è·¨ä½œå“é€‚é…æ ‡ç­¾ï¼ˆèƒ½å’Œå“ªäº›ä½œå“è”åŠ¨ï¼‰
    "crossover_types": [
        "å¤ç°æ··æ­", "ä¸­äºŒç§‘å¹»", "å®«å»·èŒåœº", "æ­¦ä¾ æ ¡å›­",
        "ä»™ä¾ ç°ä»£", "å†å²æç¬‘", "ææ€–å–œå‰§", "æˆ˜äº‰æ—¥å¸¸",
        "åŠ¨ç”»çœŸäºº", "æ—¥å‰§å›½å‰§", "æ¬§ç¾å¤é£", "ç»¼è‰ºå½±è§†"
    ],
    
    # æ‹¼æ¥å»ºè®®æ ‡ç­¾ï¼ˆåé¢é€‚åˆæ¥ä»€ä¹ˆï¼‰
    "connection_suggestions": [
        "æ¥æ‰“è„¸", "æ¥æ±‚é¥¶", "æ¥è´¨ç–‘", "æ¥å‚²å¨‡",
        "æ¥è£…å‚»", "æ¥æš´æ€’", "æ¥è®¤æ€‚", "æ¥åè½¬",
        "æ¥è§£é‡Š", "æ¥åæ§½", "æ¥ç©æ¢—", "æ¥å†·åœº"
    ]
}

def load_mashup_config() -> dict:
    config = DEFAULT_MASHUP_CONFIG.copy()
    if os.path.exists(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                user_config = json.load(f)
            for key in config.keys():
                if key in user_config and user_config[key]:
                    config[key] = user_config[key]
            print(f"âœ… æ··å‰ªé…ç½®åŠ è½½æˆåŠŸ: ç‰ˆæœ¬ {config['version']}")
        except Exception as e:
            print(f"âš ï¸ æ··å‰ªé…ç½®æ–‡ä»¶è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
    return config

MASHUP_CONFIG = load_mashup_config()
CONFIG_VERSION = MASHUP_CONFIG["version"]

# ==================== åŒç³»ç»Ÿæç¤ºè¯ ====================
def build_dual_prompt(current_line: str, context_lines: List[str]) -> Tuple[str, str]:
    """
    è¿”å›ä¸¤ä¸ªæç¤ºè¯ï¼š
    1. ä¼ ç»Ÿè¯­ä¹‰åˆ†ææç¤ºè¯ï¼ˆåŸæœ‰ç³»ç»Ÿï¼‰
    2. æ··å‰ªä¸“ç”¨åˆ†ææç¤ºè¯ï¼ˆæ–°å¢ç³»ç»Ÿï¼‰
    """
    
    # 1. ä¼ ç»Ÿè¯­ä¹‰åˆ†ææç¤ºè¯ï¼ˆä¿æŒä¸æ‚¨åŸæœ‰ç³»ç»Ÿå…¼å®¹ï¼‰
    traditional_prompt = build_traditional_prompt(current_line, context_lines)
    
    # 2. æ··å‰ªä¸“ç”¨åˆ†ææç¤ºè¯
    mashup_prompt = build_mashup_specific_prompt(current_line, context_lines)
    
    return traditional_prompt, mashup_prompt

def build_traditional_prompt(current_line: str, context_lines: List[str]) -> str:
    """ä¼ ç»Ÿè¯­ä¹‰åˆ†ææç¤ºè¯ï¼ˆä¸æ‚¨åŸæœ‰ç³»ç»Ÿå…¼å®¹ï¼‰"""
    return f"""
### ä¼ ç»Ÿè¯­ä¹‰åˆ†æ ###
è¯·åˆ†æä»¥ä¸‹å°è¯åœ¨åŸç‰‡ä¸­çš„å«ä¹‰ï¼š

å°è¯: "{current_line}"
ä¸Šä¸‹æ–‡: {json.dumps(context_lines, ensure_ascii=False)}

è¯·è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "traditional_analysis": {{
    "speech_act": "è¨€è¯­è¡Œä¸º",
    "emotion": "æƒ…æ„ŸçŠ¶æ€",
    "intent": "è¯´è¯æ„å›¾",
    "summary": "è¯­ä¹‰æ‘˜è¦"
  }}
}}
"""

def build_mashup_specific_prompt(current_line: str, context_lines: List[str]) -> str:
    """æ··å‰ªä¸“ç”¨åˆ†ææç¤ºè¯"""
    
    mashup_func_str = ", ".join(MASHUP_CONFIG["mashup_functions"])
    rhythm_str = ", ".join(MASHUP_CONFIG["editing_rhythms"])
    humor_str = ", ".join(MASHUP_CONFIG["humor_effects"])
    crossover_str = ", ".join(MASHUP_CONFIG["crossover_types"])
    conn_str = ", ".join(MASHUP_CONFIG["connection_suggestions"])
    
    return f"""
### ğŸ¬ æ··å‰ªåˆ›ä½œæ½œåŠ›åˆ†æ ###

## ä½ çš„è§’è‰²
ä½ æ˜¯èµ„æ·±å½±è§†æ··å‰ªUPä¸»ï¼Œä¸“é—¨åˆ¶ä½œè·¨ä½œå“ã€æ— å˜å¤´ã€æç¬‘å‘çš„æ··å‰ªè§†é¢‘ã€‚

## æ ¸å¿ƒä»»åŠ¡
åˆ†æä»¥ä¸‹å°è¯åœ¨**è„±ç¦»åŸç‰‡è¯­å¢ƒ**åçš„æ··å‰ªæ½œåŠ›ã€‚å¿˜è®°å®ƒåœ¨åŸç‰‡ä¸­æ˜¯ä»€ä¹ˆæ„æ€ï¼Œåªè€ƒè™‘ï¼š
1. åœ¨å…¶ä»–ä½œå“ä¸­èƒ½äº§ç”Ÿä»€ä¹ˆæç¬‘æ•ˆæœï¼Ÿ
2. é€‚åˆç”¨ä»€ä¹ˆå‰ªè¾‘æ‰‹æ³•å¤„ç†ï¼Ÿ
3. èƒ½å’Œä»€ä¹ˆç±»å‹çš„ä½œå“/å°è¯æ‹¼æ¥ï¼Ÿ

## åˆ†æå¯¹è±¡
å½“å‰å°è¯: "{current_line}"
ä¸Šä¸‹æ–‡å‚è€ƒ: {json.dumps(context_lines, ensure_ascii=False)[:200]}...

## ğŸ·ï¸ æ ‡ç­¾åº“å‚è€ƒ
æ··å‰ªåŠŸèƒ½: {mashup_func_str}
å‰ªè¾‘èŠ‚å¥: {rhythm_str}
æç¬‘æ•ˆæœ: {humor_str}
è·¨ç•Œç±»å‹: {crossover_str}
æ‹¼æ¥å»ºè®®: {conn_str}

## ğŸ“Š è¾“å‡ºè¦æ±‚ï¼ˆä¸¥æ ¼JSONæ ¼å¼ï¼‰
{{
  "mashup_analysis": {{
    // æ ¸å¿ƒæ··å‰ªåŠŸèƒ½ï¼ˆæœ€é‡è¦çš„æ ‡ç­¾ï¼‰
    "primary_function": "ä»æ··å‰ªåŠŸèƒ½æ ‡ç­¾ä¸­é€‰æ‹©",
    
    // æ¬¡è¦æ•ˆæœæ ‡ç­¾ï¼ˆå¯é€‰1-3ä¸ªï¼‰
    "secondary_tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
    
    // å‰ªè¾‘å»ºè®®
    "editing_suggestions": {{
      "rhythm": "å‰ªè¾‘èŠ‚å¥å»ºè®®",
      "visual_cue": "å»ºè®®é…åˆçš„ç”»é¢ç±»å‹",
      "audio_cue": "å»ºè®®é…åˆçš„éŸ³æ•ˆ/BGMç±»å‹",
      "special_effect": "æ˜¯å¦éœ€è¦ç‰¹æ®Šæ•ˆæœ"
    }},
    
    // æ‹¼æ¥æ½œåŠ›
    "connection_potential": {{
      "best_match": "æœ€é€‚åˆçš„æ‹¼æ¥ç±»å‹",
      "example_response": "ç¤ºä¾‹ï¼šæ¥ä»€ä¹ˆå°è¯èƒ½äº§ç”Ÿæœ€å¥½æ•ˆæœ",
      "avoid_match": "åº”é¿å…çš„æ‹¼æ¥ç±»å‹"
    }},
    
    // è·¨ä½œå“é€‚é…æ€§
    "crossover_score": {{
      "versatility": 0-10,  // é€šç”¨æ€§ï¼šèƒ½ç”¨åœ¨å¤šå°‘ä¸åŒåœºæ™¯
      "humor_value": 0-10,  // æç¬‘å€¼ï¼šèƒ½äº§ç”Ÿå¤šå¤§ç¬‘ç‚¹
      "viral_potential": 0-10,  // ä¼ æ’­æ½œåŠ›ï¼šæ˜¯å¦å®¹æ˜“æˆä¸ºæ¢—
      "recommended_genres": ["æ¨èä½œå“ç±»å‹1", "ç±»å‹2"]
    }},
    
    // å…·ä½“åˆ›æ„ç¤ºä¾‹
    "creative_examples": [
      "åˆ›æ„1ï¼šæ¯”å¦‚åœ¨XXåœºæ™¯ä¸­ï¼Œé…ä¸ŠXXç”»é¢ï¼Œæ¥XXå°è¯",
      "åˆ›æ„2ï¼šå¦ä¸€ç§ç”¨æ³•æ˜¯..."
    ],
    
    // å®ç”¨å»ºè®®
    "practical_tips": [
      "å‰ªè¾‘æŠ€å·§æç¤º1",
      "å‰ªè¾‘æŠ€å·§æç¤º2"
    ]
  }}
}}

## âœ¨ ä¼˜è´¨åˆ†ææ ‡å‡†
1. **è„‘æ´è¦å¤§**ï¼šæå‡ºæ„æƒ³ä¸åˆ°çš„æ··æ­æ–¹æ¡ˆ
2. **è¦å…·ä½“**ï¼šç»™å‡ºå…·ä½“çš„ç”»é¢ã€éŸ³æ•ˆå»ºè®®
3. **è¦å®ç”¨**ï¼šå¯¹å‰ªè¾‘å¸ˆæœ‰å®é™…æŒ‡å¯¼æ„ä¹‰
4. **è¦å‡†ç¡®**ï¼šæ ‡ç­¾é€‰æ‹©è¦ç²¾å‡†ï¼Œä¸è¦å †ç Œ

ç°åœ¨å¼€å§‹åˆ†æï¼Œç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚
"""

# ==================== åŒç³»ç»Ÿè§£æ ====================
def parse_dual_response(traditional_response: str, mashup_response: str) -> Dict:
    """è§£æåŒç³»ç»Ÿçš„å“åº”"""
    
    # è§£æä¼ ç»Ÿåˆ†æ
    traditional_data = parse_traditional_response(traditional_response)
    
    # è§£ææ··å‰ªåˆ†æ
    mashup_data = parse_mashup_response(mashup_response)
    
    # åˆå¹¶ç»“æœ
    return {
        **traditional_data,
        **mashup_data,
        "config_version": CONFIG_VERSION,
        "analysis_time": time.time()
    }

def parse_traditional_response(response_text: str) -> Dict:
    """è§£æä¼ ç»Ÿåˆ†æå“åº”"""
    try:
        clean_text = re.sub(r'```(?:json)?|```', '', response_text).strip()
        start_idx = clean_text.find('{')
        end_idx = clean_text.rfind('}')
        if start_idx != -1 and end_idx != -1:
            clean_text = clean_text[start_idx:end_idx+1]
        
        parsed = json.loads(clean_text)
        return {"traditional_analysis": parsed.get("traditional_analysis", {})}
    except Exception as e:
        print(f"âš ï¸ ä¼ ç»Ÿåˆ†æè§£æå¤±è´¥: {e}")
        return {
            "traditional_analysis": {
                "speech_act": "æœªçŸ¥",
                "emotion": "ä¸­æ€§",
                "intent": "æ— æ˜ç¡®æ„å›¾",
                "summary": "è§£æå¤±è´¥"
            }
        }

def parse_mashup_response(response_text: str) -> Dict:
    """è§£ææ··å‰ªåˆ†æå“åº”"""
    try:
        clean_text = re.sub(r'```(?:json)?|```', '', response_text).strip()
        start_idx = clean_text.find('{')
        end_idx = clean_text.rfind('}')
        if start_idx != -1 and end_idx != -1:
            clean_text = clean_text[start_idx:end_idx+1]
        
        parsed = json.loads(clean_text)
        
        # éªŒè¯å’Œè¡¥å…¨æ··å‰ªåˆ†æå­—æ®µ
        mashup_analysis = parsed.get("mashup_analysis", {})
        
        # ç¡®ä¿å…³é”®å­—æ®µå­˜åœ¨
        default_mashup = {
            "primary_function": "å…¶ä»–",
            "secondary_tags": [],
            "editing_suggestions": {
                "rhythm": "å¸¸è§„å‰ªè¾‘",
                "visual_cue": "æ— ç‰¹æ®Šè¦æ±‚",
                "audio_cue": "æ— ç‰¹æ®Šè¦æ±‚",
                "special_effect": "æ— "
            },
            "connection_potential": {
                "best_match": "æ¥å¸¸è§„å›åº”",
                "example_response": "æ— ç¤ºä¾‹",
                "avoid_match": "æ— "
            },
            "crossover_score": {
                "versatility": 5,
                "humor_value": 5,
                "viral_potential": 5,
                "recommended_genres": ["é€šç”¨"]
            },
            "creative_examples": ["æš‚æ— åˆ›æ„ç¤ºä¾‹"],
            "practical_tips": ["æŒ‰å¸¸è§„å‰ªè¾‘å³å¯"]
        }
        
        # æ·±åº¦åˆå¹¶é»˜è®¤å€¼
        def deep_merge(default, user):
            if isinstance(default, dict) and isinstance(user, dict):
                for key, value in default.items():
                    if key not in user:
                        user[key] = value
                    elif isinstance(value, dict):
                        deep_merge(value, user[key])
            return user
        
        mashup_analysis = deep_merge(default_mashup, mashup_analysis)
        
        return {"mashup_analysis": mashup_analysis}
        
    except Exception as e:
        print(f"âš ï¸ æ··å‰ªåˆ†æè§£æå¤±è´¥: {e}")
        return {
            "mashup_analysis": {
                "primary_function": "è§£æå¤±è´¥",
                "secondary_tags": [],
                "editing_suggestions": {
                    "rhythm": "å¸¸è§„å‰ªè¾‘",
                    "visual_cue": "æ— ",
                    "audio_cue": "æ— ",
                    "special_effect": "æ— "
                },
                "connection_potential": {
                    "best_match": "æ¥å¸¸è§„",
                    "example_response": "è§£æå¤±è´¥",
                    "avoid_match": "æ— "
                },
                "crossover_score": {
                    "versatility": 0,
                    "humor_value": 0,
                    "viral_potential": 0,
                    "recommended_genres": []
                },
                "creative_examples": ["åˆ†æå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨åˆ¤æ–­"],
                "practical_tips": ["åˆ†æå¤±è´¥"]
            }
        }

# ==================== åŒç³»ç»Ÿæ ‡æ³¨ ====================
def dual_annotate_with_context(current_line: str, context_lines: List[str], max_retries=2) -> Dict:
    """åŒç³»ç»Ÿæ ‡æ³¨ï¼šä¼ ç»Ÿåˆ†æ + æ··å‰ªåˆ†æ"""
    
    traditional_prompt, mashup_prompt = build_dual_prompt(current_line, context_lines)
    
    # ä¿®æ”¹ API è·¯å¾„
    CHAT_API = LLM_API.replace("/completions", "/chat/completions")
    
    traditional_result = ""
    mashup_result = ""
    
    # å¹¶è¡Œè¯·æ±‚ä¸¤ä¸ªåˆ†æï¼ˆå®é™…æ˜¯ä¸²è¡Œï¼Œä½†ç»“æ„æ¸…æ™°ï¼‰
    for attempt in range(max_retries):
        try:
            # è¯·æ±‚ä¼ ç»Ÿåˆ†æ
            trad_response = requests.post(
                CHAT_API,
                json={
                    "model": "qwen3-chat",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¼ ç»Ÿè¯­ä¹‰åˆ†æä¸“å®¶ã€‚"},
                        {"role": "user", "content": traditional_prompt}
                    ],
                    "temperature": 0.2,
                    "response_format": {"type": "json_object"}
                },
                timeout=15
            )
            trad_response.raise_for_status()
            trad_json = trad_response.json()
            traditional_result = trad_json["choices"][0]["message"]["content"].strip()
            
            # è¯·æ±‚æ··å‰ªåˆ†æ
            mashup_response = requests.post(
                CHAT_API,
                json={
                    "model": "qwen3-chat",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯æ··å‰ªåˆ›ä½œä¸“å®¶ï¼Œè„‘æ´è¦å¤§ã€‚"},
                        {"role": "user", "content": mashup_prompt}
                    ],
                    "temperature": 0.7,  # æ··å‰ªéœ€è¦æ›´å¤šåˆ›é€ æ€§
                    "response_format": {"type": "json_object"}
                },
                timeout=20
            )
            mashup_response.raise_for_status()
            mashup_json = mashup_response.json()
            mashup_result = mashup_json["choices"][0]["message"]["content"].strip()
            
            # è§£æåˆå¹¶ç»“æœ
            return parse_dual_response(traditional_result, mashup_result)
            
        except Exception as e:
            print(f"âŒ ç¬¬ {attempt+1} æ¬¡å°è¯•è¯·æ±‚å¤±è´¥: {e}")
            if attempt == max_retries - 1:
                # è¿”å›é»˜è®¤ç»“æ„
                return parse_dual_response("", "")
            time.sleep(1)

# ==================== å­—å¹•è§£æ ====================
def parse_srt(file_path: str) -> List[Dict]:
    """è§£æSRTå­—å¹•æ–‡ä»¶"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        content = f.read()
    
    blocks = re.split(r"\n\s*\n", content.strip())
    lines = []
    for block in blocks:
        parts = block.strip().split("\n")
        if len(parts) < 3: continue
        try:
            time_range = parts[1]
            text = " ".join(parts[2:]).replace("\n", " ").strip()
            if not text or "-->" not in time_range: continue
            start_str, end_str = time_range.split(" --> ")
            lines.append({
                "text": text,
                "start": _time_to_seconds(start_str),
                "end": _time_to_seconds(end_str)
            })
        except: continue
    return lines

def _time_to_seconds(time_str: str) -> float:
    h, m, s_ms = time_str.replace(",", ".").split(":")
    return float(h) * 3600 + float(m) * 60 + float(s_ms)

# ==================== å•è¡Œå¤„ç†å‡½æ•° ====================
def process_single_line(line_data, idx, total, window_size, all_lines):
    """å¤„ç†å•è¡Œå­—å¹•"""
    start_idx = max(0, idx - window_size)
    end_idx = min(total, idx + window_size + 1)
    context_texts = [all_lines[j]["text"] for j in range(start_idx, end_idx)]
    
    result = dual_annotate_with_context(line_data["text"], context_texts)
    
    return {
        "id": f"line_{idx}",
        "text": line_data["text"],
        "start": line_data["start"],
        "end": line_data["end"],
        
        # ä¼ ç»Ÿåˆ†æç»“æœ
        "traditional": result["traditional_analysis"],
        
        # æ··å‰ªåˆ†æç»“æœ
        "mashup": result["mashup_analysis"],
        
        # å…ƒæ•°æ®
        "config_version": result.get("config_version", CONFIG_VERSION),
        "analysis_time": result.get("analysis_time", time.time())
    }

# ==================== ä¸»å¤„ç†æµç¨‹ ====================
def process_srt_file(input_path: str, output_dir: str, window_size: int = 2, max_workers: int = 4):
    """ä¸»å¤„ç†å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¬ å½±è§†æ··å‰ªåŒç³»ç»Ÿè¯­ä¹‰æ ‡æ³¨å·¥å…· v3.0")
    print("ğŸ“Š åŒæ—¶è¿›è¡Œï¼šä¼ ç»Ÿè¯­ä¹‰åˆ†æ + æ··å‰ªåˆ›ä½œåˆ†æ")
    print("=" * 60)
    
    print(f"ğŸ” å¯åŠ¨åˆ†æ: {input_path}")
    print(f"âš™ï¸ ä½¿ç”¨é…ç½®ç‰ˆæœ¬: {CONFIG_VERSION}")
    
    lines = parse_srt(input_path)
    if not lines: 
        print("âŒ æœªè§£æåˆ°æœ‰æ•ˆå­—å¹•å†…å®¹")
        return
    
    total = len(lines)
    annotated_lines = [None] * total
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(process_single_line, lines[i], i, total, window_size, lines): i
            for i in range(total)
        }
        
        completed = 0
        for future in as_completed(futures):
            idx = futures[future]
            try:
                result = future.result()
                annotated_lines[idx] = result
                completed += 1
                
                # è¿›åº¦æ˜¾ç¤º
                progress_interval = max(1, total // 10)
                if completed % max(1, progress_interval) == 0:
                    elapsed = time.time() - start_time
                    speed = completed / elapsed if elapsed > 0 else 0
                    remaining = (total - completed) / speed if speed > 0 else 0
                    
                    print(f"ğŸ”„ è¿›åº¦: {completed}/{total} ({completed/total:.1%}) | "
                          f"é€Ÿåº¦: {speed:.1f}è¡Œ/ç§’ | å‰©ä½™: {remaining:.0f}ç§’")
                
                # æ˜¾ç¤ºå‰å‡ ä¸ªç¤ºä¾‹
                if completed == 2:
                    print(f"\nğŸ“ ç¤ºä¾‹åˆ†æç»“æœ:")
                    print(f"   å°è¯: {result['text'][:50]}...")
                    print(f"   ä¼ ç»Ÿåˆ†æ: {result['traditional']['speech_act']} | {result['traditional']['emotion']}")
                    print(f"   æ··å‰ªåŠŸèƒ½: {result['mashup']['primary_function']}")
                    print(f"   æç¬‘æ•ˆæœ: {', '.join(result['mashup']['secondary_tags'])}")
                    print()
                    
            except Exception as e:
                print(f"âŒ è¡Œ {idx} å¤„ç†å¤±è´¥: {e}")
                # åˆ›å»ºé»˜è®¤ç»“æœ
                annotated_lines[idx] = create_default_result(idx, lines[idx] if idx < len(lines) else None)
    
    # ç§»é™¤å¯èƒ½çš„Noneå€¼
    annotated_lines = [line for line in annotated_lines if line is not None]
    
    # ä¿å­˜å®Œæ•´ç»“æœ
    output_path = Path(output_dir) / f"{Path(input_path).stem}_dual_annotated.json"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(annotated_lines, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆç²¾ç®€ç‰ˆï¼ˆä¾¿äºå¿«é€Ÿæµè§ˆï¼‰
    simple_output = create_simple_version(annotated_lines)
    simple_path = Path(output_dir) / f"{Path(input_path).stem}_simple.json"
    with open(simple_path, "w", encoding="utf-8") as f:
        json.dump(simple_output, f, ensure_ascii=False, indent=2)
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nâœ¨ å¤„ç†å®Œæˆï¼")
    print(f"â±ï¸ æ€»è€—æ—¶: {time.time() - start_time:.1f}ç§’")
    print(f"ğŸ“ˆ å¤„ç†äº† {len(annotated_lines)} è¡Œå­—å¹•")
    print(f"ğŸ’¾ å®Œæ•´ç»“æœ: {output_path}")
    print(f"ğŸ“‹ ç²¾ç®€ç‰ˆæœ¬: {simple_path}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    show_statistics(annotated_lines)

def create_default_result(idx: int, line_data: Dict) -> Dict:
    """åˆ›å»ºé»˜è®¤ç»“æœï¼ˆå¤„ç†å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
    if line_data:
        text = line_data["text"]
        start = line_data["start"]
        end = line_data["end"]
    else:
        text = ""
        start = 0
        end = 0
    
    return {
        "id": f"line_{idx}",
        "text": text,
        "start": start,
        "end": end,
        "traditional": {
            "speech_act": "æœªçŸ¥",
            "emotion": "ä¸­æ€§",
            "intent": "æ— æ˜ç¡®æ„å›¾",
            "summary": "å¤„ç†å¤±è´¥"
        },
        "mashup": {
            "primary_function": "å…¶ä»–",
            "secondary_tags": [],
            "editing_suggestions": {
                "rhythm": "å¸¸è§„å‰ªè¾‘",
                "visual_cue": "æ— ",
                "audio_cue": "æ— ",
                "special_effect": "æ— "
            },
            "connection_potential": {
                "best_match": "æ¥å¸¸è§„",
                "example_response": "å¤„ç†å¤±è´¥",
                "avoid_match": "æ— "
            },
            "crossover_score": {
                "versatility": 0,
                "humor_value": 0,
                "viral_potential": 0,
                "recommended_genres": []
            },
            "creative_examples": ["å¤„ç†å¤±è´¥"],
            "practical_tips": ["è¯·æ‰‹åŠ¨åˆ¤æ–­"]
        },
        "config_version": CONFIG_VERSION,
        "analysis_time": time.time()
    }

def create_simple_version(annotated_lines: List[Dict]) -> List[Dict]:
    """åˆ›å»ºç²¾ç®€ç‰ˆæœ¬ï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ"""
    simple_lines = []
    for line in annotated_lines:
        simple_lines.append({
            "id": line["id"],
            "text": line["text"][:100] + ("..." if len(line["text"]) > 100 else ""),
            "traditional_summary": f"{line['traditional']['speech_act']} | {line['traditional']['emotion']}",
            "mashup_function": line["mashup"]["primary_function"],
            "humor_tags": line["mashup"]["secondary_tags"][:3],
            "editing_tip": line["mashup"]["editing_suggestions"]["rhythm"],
            "best_connection": line["mashup"]["connection_potential"]["best_match"],
            "versatility_score": line["mashup"]["crossover_score"]["versatility"],
            "humor_score": line["mashup"]["crossover_score"]["humor_value"]
        })
    return simple_lines

def show_statistics(annotated_lines: List[Dict]):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    mashup_func_counts = {}
    rhythm_counts = {}
    connection_counts = {}
    
    for line in annotated_lines:
        # ç»Ÿè®¡æ··å‰ªåŠŸèƒ½
        func = line["mashup"]["primary_function"]
        mashup_func_counts[func] = mashup_func_counts.get(func, 0) + 1
        
        # ç»Ÿè®¡å‰ªè¾‘èŠ‚å¥
        rhythm = line["mashup"]["editing_suggestions"]["rhythm"]
        rhythm_counts[rhythm] = rhythm_counts.get(rhythm, 0) + 1
        
        # ç»Ÿè®¡æ‹¼æ¥å»ºè®®
        conn = line["mashup"]["connection_potential"]["best_match"]
        connection_counts[conn] = connection_counts.get(conn, 0) + 1
    
    print(f"\nğŸ“Š æ··å‰ªåŠŸèƒ½åˆ†å¸ƒ (Top 5):")
    sorted_funcs = sorted(mashup_func_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    for func, count in sorted_funcs:
        percentage = count / len(annotated_lines) * 100
        print(f"   {func}: {count} è¡Œ ({percentage:.1f}%)")
    
    print(f"\nğŸ¬ å‰ªè¾‘èŠ‚å¥å»ºè®® (Top 3):")
    sorted_rhythms = sorted(rhythm_counts.items(), key=lambda x: x[1], reverse=True)[:3]
    for rhythm, count in sorted_rhythms:
        percentage = count / len(annotated_lines) * 100
        print(f"   {rhythm}: {count} è¡Œ ({percentage:.1f}%)")
    
    print(f"\nğŸ”— æ‹¼æ¥å»ºè®®åˆ†å¸ƒ (Top 3):")
    sorted_conns = sorted(connection_counts.items(), key=lambda x: x[1], reverse=True)[:3]
    for conn, count in sorted_conns:
        percentage = count / len(annotated_lines) * 100
        print(f"   {conn}: {count} è¡Œ ({percentage:.1f}%)")
    
    # è®¡ç®—å¹³å‡å¾—åˆ†
    avg_versatility = sum(line["mashup"]["crossover_score"]["versatility"] for line in annotated_lines) / len(annotated_lines)
    avg_humor = sum(line["mashup"]["crossover_score"]["humor_value"] for line in annotated_lines) / len(annotated_lines)
    
    print(f"\nâ­ å¹³å‡æ½œåŠ›è¯„åˆ†:")
    print(f"   é€šç”¨æ€§: {avg_versatility:.1f}/10")
    print(f"   æç¬‘å€¼: {avg_humor:.1f}/10")
    
    # æ‰¾å‡ºæœ€æœ‰æ½œåŠ›çš„å°è¯
    high_potential = []
    for line in annotated_lines:
        score = line["mashup"]["crossover_score"]["versatility"] + line["mashup"]["crossover_score"]["humor_value"]
        if score >= 15:  # æ€»åˆ†15åˆ†ä»¥ä¸Š
            high_potential.append((line["id"], line["text"][:50], score))
    
    if high_potential:
        print(f"\nğŸ’ é«˜æ½œåŠ›æ··å‰ªå°è¯ (æ€»åˆ†â‰¥15):")
        for pid, text, score in high_potential[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"   {pid}: {text}... (æ€»åˆ†: {score})")

# ==================== CLI ====================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å½±è§†å°è¯è¯­ä¹‰æ ‡æ³¨å·¥å…·-æ··å‰ªåŒç³»ç»Ÿç‰ˆ v3.0")
    parser.add_argument("input", help="SRTæ–‡ä»¶è·¯å¾„")
    parser.add_argument("output_dir", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--window", type=int, default=2, help="ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå‰åå¥æ•°ï¼‰")
    parser.add_argument("--workers", type=int, default=4, help="å¹¶å‘å¤„ç†çº¿ç¨‹æ•°")
    
    args = parser.parse_args()
    
    try:
        process_srt_file(args.input, args.output_dir, args.window, args.workers)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­å¤„ç†")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)